<!DOCTYPE html>
<head>
  <meta charset="utf-8">
  <title>Erasure Coding for Programmers, Part 2 &mdash; Store Halfword Byte-Reverse Indexed</title>
  <meta name="author" content="OzLabs">

  <link href="https://sthbrx.github.io/rss.xml" type="application/rss+xml" rel="alternate"
        title="Store Halfword Byte-Reverse Indexed RSS Feed" />





  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">


    <link href="https://sthbrx.github.io/favicon.png" rel="icon">

  <link href="https://sthbrx.github.io/theme/css/main.css" media="screen, projection"
        rel="stylesheet" type="text/css">

  <link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic"
        rel="stylesheet" type="text/css">
  <link href="//fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic"
        rel="stylesheet" type="text/css">

  <script type="text/javascript">
document.addEventListener('DOMContentLoaded', function() {
  var ts = document.createElement('span')
  ts.className = 'toggle-sidebar'
  ts = document.getElementById('content').appendChild(ts);
  ts.addEventListener('click', function(e) {
    e.preventDefault();
    body = document.getElementsByTagName('body')[0];
    bodyClasses = body.classList.toggle('collapse-sidebar');
  });
  var sections = document.querySelectorAll('aside.sidebar > section');
  if (sections.length > 1) {
    for (index = 0; index < sections.length; index++) {
      section = sections[index];
      if ((sections.length >= 3) && index % 3 === 0) {
        section.classList.add("first");
      }
      var count = ((index +1) % 2) ? "odd" : "even";
      section.classList.add(count);
    }
  }
  if (sections.length >= 3) {
    document.querySelector('aside.sidebar').classList.add('thirds');
  }
});
  </script>
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-91189608-1', 'auto');

    ga('send', 'pageview');
    </script>
</head>

<body>
  <header role="banner"><hgroup>
  <h1><a href="https://sthbrx.github.io/">Store Halfword Byte-Reverse Indexed</a></h1>
    <h2>A Power Technical Blog</h2>
</hgroup></header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="https://sthbrx.github.io/rss.xml" rel="subscribe-rss">RSS</a></li>
</ul>


<ul class="main-navigation">
      <li class="active">
        <a href="https://sthbrx.github.io/category/development.html">Development</a>
      </li>
      <li >
        <a href="https://sthbrx.github.io/category/education.html">Education</a>
      </li>
      <li >
        <a href="https://sthbrx.github.io/category/openpower.html">OpenPOWER</a>
      </li>
      <li >
        <a href="https://sthbrx.github.io/category/performance.html">Performance</a>
      </li>
      <li >
        <a href="https://sthbrx.github.io/category/petitboot.html">Petitboot</a>
      </li>
      <li >
        <a href="https://sthbrx.github.io/category/snowpatch.html">snowpatch</a>
      </li>
      <li >
        <a href="https://sthbrx.github.io/category/virtualisation-and-emulation.html">Virtualisation and Emulation</a>
      </li>
</ul></nav>
  <div id="main">
    <div id="content">
<div>
  <article class="hentry" role="article">
<header>
      <h1 class="entry-title">Erasure Coding for Programmers, Part 2</h1>
    <p class="meta">
<time datetime="2017-03-24T10:08:00+11:00" pubdate>Fri 24 March 2017</time>    </p>
</header>

  <div class="byline_index">
<p class="meta">
  <span class="byline author vcard">
    Posted by <span class="fn">
          <a href="https://sthbrx.github.io/author/daniel-axtens.html">Daniel Axtens</a>
    </span>
  </span>
<time datetime="2017-03-24T10:08:00+11:00" pubdate>Fri 24 March 2017</time>  <span class="categories">
    <a class='category' href='https://sthbrx.github.io/category/development.html'>Development</a>
  </span>
  <span class="categories">
    <a class="category" href="https://sthbrx.github.io/tag/erasure.html">erasure</a>,    <a class="category" href="https://sthbrx.github.io/tag/raid.html">raid</a>,    <a class="category" href="https://sthbrx.github.io/tag/storage.html">storage</a>  </span>
</p>  </div>
  <div class="entry-content"><p>We left <a href="/blog/2017/03/20/erasure-coding-for-programmers-part-1/">part 1</a> having explored GF(2^8) and RAID 6, and asking the question "what does all this have to do with Erasure Codes?"</p>
<p>Basically, the thinking goes "RAID 6 is cool, but what if, instead of two parity disks, we had an arbitrary number of parity disks?"</p>
<p>How would we do that? Well, let's introduce our new best friend: Coding Theory!</p>
<p>Say we want to transmit some data across an error-prone medium. We don't know where the errors might occur, so we add some extra information to allow us to detect and possibly correct for errors. This is a code. Codes are a largish field of engineering, but rather than show off my knowledge about systematic linear block codes, let's press on.</p>
<p>Today, our error-prone medium is an array of inexpensive disks. Now we make this really nice assumption about disks, namely that they are either perfectly reliable or completely missing. In other words, we consider that a disk will either be present or 'erased'. We come up with 'erasure codes' that are able to reconstruct data when it is known to be missing. (This is a slightly different problem to being able to verify and correct data that might or might not be subtly corrupted. Disks also have to deal with this problem, but it is <em>not</em> something erasure codes address!)</p>
<p>The particular code we use is a Reed-Solomon code. The specific details are unimportant, but there's a really good graphical outline of the broad concepts in sections 1 and 3 of <a href="http://jerasure.org/jerasure-2.0/">the Jerasure paper/manual</a>. (Don't go on to section 4.)</p>
<p>That should give you some background on how this works at a pretty basic mathematical level. Implementation is a matter of mapping that maths (matrix multiplication) onto hardware primitives, and making it go fast.</p>
<h2>Scope</h2>
<p>I'm deliberately <em>not</em> covering some pretty vast areas of what would be required to write your own erasure coding library from scratch. I'm not going to talk about how to compose the matricies, how to invert them, or anything like that. I'm not sure how that would be a helpful exercise - ISA-L and jerasure already exist and do that for you.</p>
<p>What I want to cover is an efficient implementation of the some algorithms, once you have the matricies nailed down.</p>
<p>I'm also going to assume your library already provides a generic multiplication function in GF(2^8). That's required to construct the matrices, so it's a pretty safe assumption.</p>
<h2>The beginnings of an API</h2>
<p>Let's make this a bit more concrete.</p>
<p>This will be heavily based on the <a href="https://01.org/intel%C2%AE-storage-acceleration-library-open-source-version/documentation/isa-l-open-source-api">ISA-L API</a> but you probably want to plug into ISA-L anyway, so that shouldn't be a problem.</p>
<p>What I want to do is build up from very basic algorithmic components into something useful.</p>
<p>The first thing we want to do is to be able to is Galois Field multiplication of an entire region of bytes by an arbitrary constant.</p>
<p>We basically want <code>gf_vect_mul(size_t len, &lt;something representing the constant&gt;, unsigned char * src, unsigned char * dest)</code></p>
<h3>Simple and slow approach</h3>
<p>The simplest way is to do something like this:</p>
<div class="highlight"><pre><span></span><code><span class="n">void</span><span class="w"> </span><span class="n">gf_vect_mul_simple</span><span class="p">(</span><span class="n">size_t</span><span class="w"> </span><span class="nf">len</span><span class="p">,</span><span class="w"> </span><span class="n">unsigned</span><span class="w"> </span><span class="nc">char</span><span class="w"> </span><span class="n">c</span><span class="p">,</span><span class="w"> </span><span class="n">unsigned</span><span class="w"> </span><span class="nc">char</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">src</span><span class="p">,</span><span class="w"> </span><span class="n">unsigned</span><span class="w"> </span><span class="nc">char</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">dest</span><span class="p">)</span><span class="w"> </span><span class="err">{</span><span class="w"></span>

<span class="w">    </span><span class="n">size_t</span><span class="w"> </span><span class="n">i</span><span class="p">;</span><span class="w"></span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">&lt;</span><span class="nf">len</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="err">{</span><span class="w"></span>
<span class="w">        </span><span class="n">dest</span><span class="o">[</span><span class="n">i</span><span class="o">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">gf_mul</span><span class="p">(</span><span class="n">c</span><span class="p">,</span><span class="w"> </span><span class="n">src</span><span class="o">[</span><span class="n">i</span><span class="o">]</span><span class="p">);</span><span class="w"></span>
<span class="w">    </span><span class="err">}</span><span class="w"></span>
<span class="err">}</span><span class="w"></span>
</code></pre></div>

<p>That does multiplication element by element using the library's supplied <code>gf_mul</code> function, which - as the name suggests - does GF(2^8) multiplication of a scalar by a scalar.</p>
<p>This works. The problem is that it is very, painfully, slow - in the order of a few hundred megabytes per second.</p>
<h3>Going faster</h3>
<p>How can we make this faster?</p>
<p>There are a few things we can try: if you want to explore a whole range of different ways to do this, check out the <a href="http://jerasure.org/gf-complete-1.02/">gf-complete</a> project. I'm going to assume we want to skip right to the end and know what is the fastest we've found.</p>
<p>Cast your mind back to the <a href="https://www.kernel.org/pub/linux/kernel/people/hpa/raid6.pdf">RAID 6 paper</a> (PDF). I talked about in <a href="/blog/2017/03/20/erasure-coding-for-programmers-part-1/">part 1</a>. That had a way of doing an efficient multiplication in GF(2^8) using vector instructions.</p>
<p>To refresh your memory, we split the multiplication into two parts - low bits and high bits, looked them up separately in a lookup table, and joined them with XOR. We then discovered that on modern Power chips, we could do that in one instruction with <code>vpermxor</code>.</p>
<p>So, a very simple way to do this would be:</p>
<ul>
<li>generate the table for <code>a</code></li>
<li>for each 16-byte chunk of our input:<ul>
<li>load the input</li>
<li>do the <code>vpermxor</code> with the table</li>
<li>save it out</li>
</ul>
</li>
</ul>
<p>Generating the tables is reasonably straight-forward, in theory. Recall that the tables are <code>a</code> * {{00},{01},...,{0f}} and <code>a</code> * {{00},{10},..,{f0}} - a couple of loops in C will generate them without difficulty. ISA-L has a function to do this, as does gf-complete in split-table mode, so I won't repeat them here.</p>
<p>So, let's recast our function to take the tables as an input rather than the constant <code>a</code>. Assume we're provided the two tables concatenated into one 32-byte chunk. That would give us:</p>
<div class="highlight"><pre><span></span><code><span class="err">void gf_vect_mul_v2(size_t len, unsigned char * table, unsigned char * src, unsigned char * dest)</span>
</code></pre></div>

<p>Here's how you would do it in C:</p>
<div class="highlight"><pre><span></span><code><span class="n">void</span> <span class="n">gf_vect_mul_v2</span><span class="p">(</span><span class="n">size_t</span> <span class="n">len</span><span class="p">,</span> <span class="n">unsigned</span> <span class="nb">char</span> <span class="o">*</span> <span class="k">table</span><span class="p">,</span> <span class="n">unsigned</span> <span class="nb">char</span> <span class="o">*</span> <span class="n">src</span><span class="p">,</span> <span class="n">unsigned</span> <span class="nb">char</span> <span class="o">*</span> <span class="n">dest</span><span class="p">)</span> <span class="err">{</span>
        <span class="n">vector</span> <span class="n">unsigned</span> <span class="nb">char</span> <span class="n">tbl1</span><span class="p">,</span> <span class="n">tbl2</span><span class="p">,</span> <span class="k">in</span><span class="p">,</span> <span class="k">out</span><span class="p">;</span>
        <span class="n">size_t</span> <span class="n">i</span><span class="p">;</span>

        <span class="cm">/* Assume table, src, dest are aligned and len is a multiple of 16 */</span>

        <span class="n">tbl1</span> <span class="o">=</span> <span class="n">vec_ld</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="k">table</span><span class="p">);</span>
        <span class="n">tbl2</span> <span class="o">=</span> <span class="n">vec_ld</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="k">table</span><span class="p">);</span>
        <span class="k">for</span> <span class="p">(</span><span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">i</span><span class="o">&lt;</span><span class="n">len</span><span class="p">;</span> <span class="n">i</span><span class="o">+=</span><span class="mi">16</span><span class="p">)</span> <span class="err">{</span>
            <span class="k">in</span> <span class="o">=</span> <span class="n">vec_ld</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">unsigned</span> <span class="nb">char</span> <span class="o">*</span><span class="p">)</span><span class="n">src</span><span class="p">);</span>
            <span class="n">__asm__</span><span class="p">(</span><span class="ss">&quot;vpermxor %0, %1, %2, %3&quot;</span> <span class="p">:</span> <span class="ss">&quot;=v&quot;</span><span class="p">(</span><span class="k">out</span><span class="p">)</span> <span class="p">:</span> <span class="ss">&quot;v&quot;</span><span class="p">(</span><span class="n">tbl1</span><span class="p">),</span> <span class="ss">&quot;v&quot;</span><span class="p">(</span><span class="n">tbl2</span><span class="p">),</span> <span class="ss">&quot;v&quot;</span><span class="p">(</span><span class="k">in</span><span class="p">)</span>
            <span class="n">vec_st</span><span class="p">(</span><span class="k">out</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">unsigned</span> <span class="nb">char</span> <span class="o">*</span><span class="p">)</span><span class="n">dest</span><span class="p">);</span>
        <span class="err">}</span>
<span class="err">}</span>
</code></pre></div>

<p>There's a few quirks to iron out - making sure the table is laid out in the vector register in the way you expect, etc, but that generally works and is quite fast - my Power 8 VM does about 17-18 GB/s with non-cache-contained data with this implementation.</p>
<p>We can go a bit faster by doing larger chunks at a time:</p>
<div class="highlight"><pre><span></span><code><span class="err">    for (i=0; i&lt;vlen; i+=64) {</span>
<span class="err">            in1 = vec_ld(i, (unsigned char *)src);</span>
<span class="err">            in2 = vec_ld(i+16, (unsigned char *)src);</span>
<span class="err">            in3 = vec_ld(i+32, (unsigned char *)src);</span>
<span class="err">            in4 = vec_ld(i+48, (unsigned char *)src);</span>
<span class="err">            __asm__(&quot;vpermxor %0, %1, %2, %3&quot; : &quot;=v&quot;(out1) : &quot;v&quot;(tbl1), &quot;v&quot;(tbl2), &quot;v&quot;(in1));</span>
<span class="err">            __asm__(&quot;vpermxor %0, %1, %2, %3&quot; : &quot;=v&quot;(out2) : &quot;v&quot;(tbl1), &quot;v&quot;(tbl2), &quot;v&quot;(in2));</span>
<span class="err">            __asm__(&quot;vpermxor %0, %1, %2, %3&quot; : &quot;=v&quot;(out3) : &quot;v&quot;(tbl1), &quot;v&quot;(tbl2), &quot;v&quot;(in3));</span>
<span class="err">            __asm__(&quot;vpermxor %0, %1, %2, %3&quot; : &quot;=v&quot;(out4) : &quot;v&quot;(tbl1), &quot;v&quot;(tbl2), &quot;v&quot;(in4));</span>
<span class="err">            vec_st(out1, i, (unsigned char *)dest);</span>
<span class="err">            vec_st(out2, i+16, (unsigned char *)dest);</span>
<span class="err">            vec_st(out3, i+32, (unsigned char *)dest);</span>
<span class="err">            vec_st(out4, i+48, (unsigned char *)dest);</span>
<span class="err">    }</span>
</code></pre></div>

<p>This goes at about 23.5 GB/s.</p>
<p>We can go one step further and do the core loop in assembler - that means we control the instruction layout and so on. I tried this: it turns out that for the basic vector multiply loop, if we turn off ASLR and pin to a particular CPU, we can see a improvement of a few percent (and a decrease in variability) over C code.</p>
<h2>Building from vector multiplication</h2>
<p>Once you're comfortable with the core vector multiplication, you can start to build more interesting routines.</p>
<p>A particularly useful one on Power turned out to be the multiply and add routine: like gf_vect_mul, except that rather than overwriting the output, it loads the output and xors the product in. This is a simple extension of the gf_vect_mul function so is left as an exercise to the reader.</p>
<p>The next step would be to start building erasure coding proper. Recall that to get an element of our output, we take a dot product: we take the corresponding input element of each disk, multiply it with the corresponding GF(2^8) coding matrix element and sum all those products. So all we need now is a dot product algorithm.</p>
<p>One approach is the conventional dot product:</p>
<ul>
<li>for each element<ul>
<li>zero accumulator</li>
<li>for each source<ul>
<li>load <code>input[source][element]</code></li>
<li>do GF(2^8) multiplication</li>
<li>xor into accumulator</li>
</ul>
</li>
<li>save accumulator to <code>output[element]</code></li>
</ul>
</li>
</ul>
<p>The other approach is multiply and add:</p>
<ul>
<li>for each source<ul>
<li>for each element<ul>
<li>load <code>input[source][element]</code></li>
<li>do GF(2^8) multiplication</li>
<li>load <code>output[element]</code></li>
<li>xor in product</li>
<li>save <code>output[element]</code></li>
</ul>
</li>
</ul>
</li>
</ul>
<p>The dot product approach has the advantage of fewer writes. The multiply and add approach has the advantage of better cache/prefetch performance. The approach you ultimately go with will probably depend on the characteristics of your machine and the length of data you are dealing with.</p>
<p>For what it's worth, ISA-L ships with only the first approach in x86 assembler, and Jerasure leans heavily towards the second approach.</p>
<p>Once you have a vector dot product sorted, you can build a full erasure coding setup: build your tables with your library, then do a dot product to generate each of your outputs!</p>
<p>In ISA-L, this is implemented something like this:</p>
<div class="highlight"><pre><span></span><code><span class="err">/*</span>
<span class="err"> * ec_encode_data_simple(length of each data input, number of inputs,</span>
<span class="err"> *                       number of outputs, pre-generated GF(2^8) tables,</span>
<span class="err"> *                       input data pointers, output code pointers)</span>
<span class="err"> */</span>
<span class="err">void ec_encode_data_simple(int len, int k, int rows, unsigned char *g_tbls,</span>
<span class="err">                           unsigned char **data, unsigned char **coding)</span>
<span class="err">{</span>
<span class="err">        while (rows) {</span>
<span class="err">                gf_vect_dot_prod(len, k, g_tbls, data, *coding);</span>
<span class="err">                g_tbls += k * 32;</span>
<span class="err">                coding++;</span>
<span class="err">                rows--;</span>
<span class="err">        }</span>
<span class="err">}</span>
</code></pre></div>

<h2>Going faster still</h2>
<p>Eagle eyed readers will notice that however we generate an output, we have to read all the input elements. This means that if we're doing a code with 10 data disks and 4 coding disks, we have to read each of the 10 inputs 4 times.</p>
<p>We could do better if we could calculate multiple outputs for each pass through the inputs. This is a little fiddly to implement, but does lead to a speed improvement.</p>
<p>ISA-L is an excellent example here. Intel goes up to 6 outputs at once: the number of outputs you can do is only limited by how many vector registers you have to put the various operands and results in.</p>
<h2>Tips and tricks</h2>
<ul>
<li>
<p>Benchmarking is tricky. I do the following on a bare-metal, idle machine, with ASLR off and pinned to an arbitrary hardware thread. (Code is for the <a href="https://fishshell.com/">fish shell</a>)</p>
<div class="highlight"><pre><span></span><code><span class="err">for x in (seq 1 50)</span>
<span class="err">    setarch ppc64le -R taskset -c 24 erasure_code/gf_vect_mul_perf</span>
<span class="err">end | awk &#39;/MB/ {sum+=$13} END {print sum/50, &quot;MB/s&quot;}&#39;</span>
</code></pre></div>

</li>
<li>
<p>Debugging is tricky; the more you can do in C and the less you do in assembly, the easier your life will be.</p>
</li>
<li>
<p>Vector code is notoriously alignment-sensitive - if you can't figure out why something is wrong, check alignment. (Pro-tip: ISA-L does <em>not</em> guarantee the alignment of the <code>gftbls</code> parameter, and many of the tests supply an unaligned table from the stack. For testing <code>__attribute__((aligned(16)))</code> is your friend!)</p>
</li>
<li>
<p>Related: GCC is moving towards assignment over vector intrinsics, at least on Power:</p>
<div class="highlight"><pre><span></span><code><span class="err">vector unsigned char a;</span>
<span class="err">unsigned char * data;</span>
<span class="err">// good, also handles word-aligned data with VSX</span>
<span class="err">a = *(vector unsigned char *)data;</span>
<span class="err">// bad, requires special handling of non-16-byte aligned data</span>
<span class="err">a = vec_ld(0, (unsigned char *) data);</span>
</code></pre></div>

</li>
</ul>
<h2>Conclusion</h2>
<p>Hopefully by this point you're equipped to figure out how your erasure coding library of choice works, and write your own optimised implementation (or maintain an implementation written by someone else).</p>
<p>I've referred to a number of resources throughout this series:</p>
<ul>
<li>ISA-L <a href="https://github.com/01org/isa-l">code</a>, <a href="">API description</a></li>
<li>Jerasure <a href="http://jerasure.org/">code</a>, <a href="http://jerasure.org/jerasure-2.0/">docs</a></li>
<li>gf-complete <a href="http://jerasure.org/">code</a>, <a href="http://jerasure.org/gf-complete-1.02/">docs</a> </li>
<li><a href="https://www.kernel.org/pub/linux/kernel/people/hpa/raid6.pdf">The mathematics of RAID-6</a> (PDF), H. Peter Anvin</li>
</ul>
<p>If you want to go deeper, I also read the following and found them quite helpful in understanding Galois Fields and Reed-Solomon coding:</p>
<ul>
<li><a href="https://ntrs.nasa.gov/archive/nasa/casi.ntrs.nasa.gov/19900019023.pdf">Tutorial on Reed-Solomon Error Correction Coding</a> (PDF), William A. Geisel, NASA</li>
<li><a href="https://ntrs.nasa.gov/archive/nasa/casi.ntrs.nasa.gov/19900019023.pdf">Reed-Solomon error correction</a> (PDF), BBC R&amp;D White Paper WHP 031, C. K. P. Clarke.</li>
</ul>
<p>For a more rigorous mathematical approach to rings and fields, a university mathematics course may be of interest. For more on coding theory, a university course in electronics engineering may be helpful.</p></div>
    <footer>
<div class="sharing">
</div>    </footer>
  </article>

  <section>
    <h1>Comments</h1>
    <div id="disqus_thread" aria-live="polite"><noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div>
  </section>
</div>
<aside class="sidebar">
  <section>
    <h1>Recent Posts</h1>
    <ul id="recent_posts">
      <li class="post">
          <a href="https://sthbrx.github.io/blog/2021/06/14/fuzzing-grub-part-2-going-faster/">Fuzzing grub, part 2: going faster</a>
      </li>
      <li class="post">
          <a href="https://sthbrx.github.io/blog/2021/03/04/fuzzing-grub-part-1/">Fuzzing grub: part 1</a>
      </li>
      <li class="post">
          <a href="https://sthbrx.github.io/blog/2020/01/22/linuxconfau-2020-recap/">linux.conf.au 2020 recap</a>
      </li>
      <li class="post">
          <a href="https://sthbrx.github.io/blog/2019/12/18/rfid-and-hrfid/">rfid and hrfid</a>
      </li>
      <li class="post">
          <a href="https://sthbrx.github.io/blog/2019/06/18/ten-thousand-disks/">TEN THOUSAND DISKS</a>
      </li>
    </ul>
  </section>
  <section>
      
    <h1>Categories</h1>
    <ul id="recent_posts">
        <li><a href="https://sthbrx.github.io/category/development.html">Development</a></li>
        <li><a href="https://sthbrx.github.io/category/education.html">Education</a></li>
        <li><a href="https://sthbrx.github.io/category/openpower.html">OpenPOWER</a></li>
        <li><a href="https://sthbrx.github.io/category/performance.html">Performance</a></li>
        <li><a href="https://sthbrx.github.io/category/petitboot.html">Petitboot</a></li>
        <li><a href="https://sthbrx.github.io/category/snowpatch.html">snowpatch</a></li>
        <li><a href="https://sthbrx.github.io/category/virtualisation-and-emulation.html">Virtualisation and Emulation</a></li>
    </ul>
  </section>
 

  <section>
  <h1>Tags</h1>
    <a href="https://sthbrx.github.io/tag/testing.html">testing</a>,    <a href="https://sthbrx.github.io/tag/conferences.html">conferences</a>,    <a href="https://sthbrx.github.io/tag/instruction-set-architecture.html">Instruction Set Architecture</a>,    <a href="https://sthbrx.github.io/tag/openpower.html">openpower</a>,    <a href="https://sthbrx.github.io/tag/linux.html">linux</a>,    <a href="https://sthbrx.github.io/tag/firmware.html">firmware</a>,    <a href="https://sthbrx.github.io/tag/goodposts.html">goodposts</a>,    <a href="https://sthbrx.github.io/tag/realcontent.html">realcontent</a>,    <a href="https://sthbrx.github.io/tag/madposting.html">madposting</a>,    <a href="https://sthbrx.github.io/tag/op-test.html">op-test</a>,    <a href="https://sthbrx.github.io/tag/qemu.html">qemu</a>,    <a href="https://sthbrx.github.io/tag/pci.html">pci</a>,    <a href="https://sthbrx.github.io/tag/sparseposting.html">sparseposting</a>,    <a href="https://sthbrx.github.io/tag/petitboot.html">petitboot</a>,    <a href="https://sthbrx.github.io/tag/security.html">security</a>,    <a href="https://sthbrx.github.io/tag/vscode.html">vscode</a>,    <a href="https://sthbrx.github.io/tag/code.html">code</a>,    <a href="https://sthbrx.github.io/tag/openbmc.html">openbmc</a>,    <a href="https://sthbrx.github.io/tag/ipmi.html">ipmi</a>,    <a href="https://sthbrx.github.io/tag/opencapi.html">opencapi</a>,    <a href="https://sthbrx.github.io/tag/openpower-summit.html">openpower summit</a>,    <a href="https://sthbrx.github.io/tag/easyposts.html">easyposts</a>,    <a href="https://sthbrx.github.io/tag/linuxboot.html">linuxboot</a>,    <a href="https://sthbrx.github.io/tag/google.html">google</a>,    <a href="https://sthbrx.github.io/tag/intel.html">intel</a>,    <a href="https://sthbrx.github.io/tag/osfc.html">osfc</a>,    <a href="https://sthbrx.github.io/tag/shortposts.html">shortposts</a>,    <a href="https://sthbrx.github.io/tag/facebook.html">facebook</a>,    <a href="https://sthbrx.github.io/tag/performance.html">performance</a>,    <a href="https://sthbrx.github.io/tag/phoronix.html">phoronix</a>,    <a href="https://sthbrx.github.io/tag/benchmarks.html">benchmarks</a>,    <a href="https://sthbrx.github.io/tag/kernel.html">kernel</a>,    <a href="https://sthbrx.github.io/tag/stupid-ideas.html">stupid ideas</a>,    <a href="https://sthbrx.github.io/tag/network.html">network</a>,    <a href="https://sthbrx.github.io/tag/power.html">power</a>,    <a href="https://sthbrx.github.io/tag/xdp.html">xdp</a>,    <a href="https://sthbrx.github.io/tag/networking.html">networking</a>,    <a href="https://sthbrx.github.io/tag/remoteposts.html">remoteposts</a>,    <a href="https://sthbrx.github.io/tag/ceph.html">ceph</a>,    <a href="https://sthbrx.github.io/tag/raid.html">raid</a>,    <a href="https://sthbrx.github.io/tag/storage.html">storage</a>,    <a href="https://sthbrx.github.io/tag/erasure.html">erasure</a>,    <a href="https://sthbrx.github.io/tag/lustre.html">lustre</a>,    <a href="https://sthbrx.github.io/tag/hpc.html">hpc</a>,    <a href="https://sthbrx.github.io/tag/nvlink.html">nvlink</a>,    <a href="https://sthbrx.github.io/tag/namd.html">namd</a>,    <a href="https://sthbrx.github.io/tag/cuda.html">cuda</a>,    <a href="https://sthbrx.github.io/tag/gpu.html">gpu</a>,    <a href="https://sthbrx.github.io/tag/minsky.html">minsky</a>,    <a href="https://sthbrx.github.io/tag/s822lc-for-hpc.html">S822LC for hpc</a>,    <a href="https://sthbrx.github.io/tag/debug.html">debug</a>,    <a href="https://sthbrx.github.io/tag/virtualisation.html">virtualisation</a>,    <a href="https://sthbrx.github.io/tag/dmesg.html">dmesg</a>,    <a href="https://sthbrx.github.io/tag/printk.html">printk</a>,    <a href="https://sthbrx.github.io/tag/boot.html">boot</a>,    <a href="https://sthbrx.github.io/tag/early.html">early</a>,    <a href="https://sthbrx.github.io/tag/error.html">error</a>,    <a href="https://sthbrx.github.io/tag/centos.html">centos</a>,    <a href="https://sthbrx.github.io/tag/centos7.html">centos7</a>,    <a href="https://sthbrx.github.io/tag/p8.html">p8</a>,    <a href="https://sthbrx.github.io/tag/bmc.html">bmc</a>,    <a href="https://sthbrx.github.io/tag/rhel.html">RHEL</a>,    <a href="https://sthbrx.github.io/tag/skiroot.html">skiroot</a>,    <a href="https://sthbrx.github.io/tag/devmapper.html">devmapper</a>,    <a href="https://sthbrx.github.io/tag/lvm.html">lvm</a>,    <a href="https://sthbrx.github.io/tag/cgroups.html">cgroups</a>,    <a href="https://sthbrx.github.io/tag/numa.html">numa</a>,    <a href="https://sthbrx.github.io/tag/development.html">Development</a>,    <a href="https://sthbrx.github.io/tag/netboot.html">netboot</a>,    <a href="https://sthbrx.github.io/tag/pxe.html">pxe</a>,    <a href="https://sthbrx.github.io/tag/education.html">Education</a>,    <a href="https://sthbrx.github.io/tag/work-experience.html">work experience</a>,    <a href="https://sthbrx.github.io/tag/asm.html">asm</a>,    <a href="https://sthbrx.github.io/tag/vdso.html">vdso</a>,    <a href="https://sthbrx.github.io/tag/snowpatch.html">snowpatch</a>,    <a href="https://sthbrx.github.io/tag/tools.html">tools</a>,    <a href="https://sthbrx.github.io/tag/intern.html">intern</a>,    <a href="https://sthbrx.github.io/tag/srop.html">SROP</a>,    <a href="https://sthbrx.github.io/tag/mitigation.html">mitigation</a>,    <a href="https://sthbrx.github.io/tag/double.html">double</a>,    <a href="https://sthbrx.github.io/tag/float.html">float</a>,    <a href="https://sthbrx.github.io/tag/hex.html">hex</a>,    <a href="https://sthbrx.github.io/tag/debugging.html">debugging</a>,    <a href="https://sthbrx.github.io/tag/skiboot.html">skiboot</a>,    <a href="https://sthbrx.github.io/tag/opal.html">OPAL</a>,    <a href="https://sthbrx.github.io/tag/fsp.html">FSP</a>,    <a href="https://sthbrx.github.io/tag/patches.html">patches</a>,    <a href="https://sthbrx.github.io/tag/based16.html">based16</a>,    <a href="https://sthbrx.github.io/tag/linux-gods.html">Linux Gods</a>,    <a href="https://sthbrx.github.io/tag/ozlabs.html">Ozlabs</a>,    <a href="https://sthbrx.github.io/tag/offtopic.html">offtopic</a>,    <a href="https://sthbrx.github.io/tag/autoboot.html">autoboot</a>,    <a href="https://sthbrx.github.io/tag/kexec.html">kexec</a>,    <a href="https://sthbrx.github.io/tag/aufs.html">aufs</a>,    <a href="https://sthbrx.github.io/tag/overlay.html">overlay</a>,    <a href="https://sthbrx.github.io/tag/php.html">php</a>,    <a href="https://sthbrx.github.io/tag/capi.html">capi</a>  </section>

  <section>
    <h1><a href="https://sthbrx.github.io/authors.html">Authors</a></h1>
    <ul id="authors_list">
        <li><a href="https://sthbrx.github.io/author/alastair-dsilva.html">Alastair D'Silva</a></li>
        <li><a href="https://sthbrx.github.io/author/andrew-donnellan.html">Andrew Donnellan</a></li>
        <li><a href="https://sthbrx.github.io/author/anton-blanchard.html">Anton Blanchard</a></li>
        <li><a href="https://sthbrx.github.io/author/callum-scarvell.html">Callum Scarvell</a></li>
        <li><a href="https://sthbrx.github.io/author/cyril-bur.html">Cyril Bur</a></li>
        <li><a href="https://sthbrx.github.io/author/daniel-axtens.html">Daniel Axtens</a></li>
        <li><a href="https://sthbrx.github.io/author/daniel-black.html">Daniel Black</a></li>
        <li><a href="https://sthbrx.github.io/author/joel-stanley.html">Joel Stanley</a></li>
        <li><a href="https://sthbrx.github.io/author/nick-piggin.html">Nick Piggin</a></li>
        <li><a href="https://sthbrx.github.io/author/rashmica-gupta.html">Rashmica Gupta</a></li>
        <li><a href="https://sthbrx.github.io/author/rohan-mclure.html">Rohan McLure</a></li>
        <li><a href="https://sthbrx.github.io/author/russell-currey.html">Russell Currey</a></li>
        <li><a href="https://sthbrx.github.io/author/samuel-mendoza-jonas.html">Samuel Mendoza-Jonas</a></li>
        <li><a href="https://sthbrx.github.io/author/suraj-jitindar-singh.html">Suraj Jitindar Singh</a></li>
    </ul>
  </section>


    <section>
        <h1>Social</h1>
        <ul>
            <li><a href="https://sthbrx.github.io/rss.xml" type="application/rss+xml" rel="alternate">RSS</a></li>
            <li><a href="https://github.com/sthbrx/" target="_blank">GitHub</a></li>
            <li><a href="https://lists.ozlabs.org/listinfo/linuxppc-dev" target="_blank">linuxppc mailing list</a></li>
            <li><a href="https://lists.ozlabs.org/listinfo/skiboot" target="_blank">Skiboot mailing list</a></li>
        </ul>
    </section>
    <section>
        <h1>Blogroll</h1>
        <ul>
            <li><a href="http://ozlabs.org" target="_blank">OzLabs</a></li>
        </ul>
    </section>

    <section>
        <h1>Disclaimer</h1>
        <div>
This blog represents the views of the individual authors, and doesn't necessarily represent IBM's positions, strategies or opinions.        </div>
    </section>
</aside>    </div>
  </div>
  <footer role="contentinfo"><p>
    Copyright &copy;  2015&ndash;2021  OzLabs &mdash;
  <span class="credit">Powered by <a href="http://getpelican.com">Pelican</a></span>
</p></footer>
  <script type="text/javascript">
    var disqus_shortname = 'sthbrx';
    var disqus_identifier = '/blog/2017/03/24/erasure-coding-for-programmers-part-2/';
    var disqus_url = 'https://sthbrx.github.io/blog/2017/03/24/erasure-coding-for-programmers-part-2/';
    var disqus_title = 'Erasure Coding for Programmers, Part 2';
    (function() {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = "//" + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
     })();
  </script>
</body>
</html>