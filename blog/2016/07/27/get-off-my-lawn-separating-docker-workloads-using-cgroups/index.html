<!DOCTYPE html>
<head>
  <meta charset="utf-8">
  <title>Get off my lawn: separating Docker workloads using cgroups &mdash; Store Halfword Byte-Reverse Indexed</title>
  <meta name="author" content="OzLabs">

  <link href="https://sthbrx.github.io/rss.xml" type="application/rss+xml" rel="alternate"
        title="Store Halfword Byte-Reverse Indexed RSS Feed" />





  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">


    <link href="https://sthbrx.github.io/favicon.png" rel="icon">

  <link href="https://sthbrx.github.io/theme/css/main.css" media="screen, projection"
        rel="stylesheet" type="text/css">

  <link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic"
        rel="stylesheet" type="text/css">
  <link href="//fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic"
        rel="stylesheet" type="text/css">

  <script type="text/javascript">
document.addEventListener('DOMContentLoaded', function() {
  var ts = document.createElement('span')
  ts.className = 'toggle-sidebar'
  ts = document.getElementById('content').appendChild(ts);
  ts.addEventListener('click', function(e) {
    e.preventDefault();
    body = document.getElementsByTagName('body')[0];
    bodyClasses = body.classList.toggle('collapse-sidebar');
  });
  var sections = document.querySelectorAll('aside.sidebar > section');
  if (sections.length > 1) {
    for (index = 0; index < sections.length; index++) {
      section = sections[index];
      if ((sections.length >= 3) && index % 3 === 0) {
        section.classList.add("first");
      }
      var count = ((index +1) % 2) ? "odd" : "even";
      section.classList.add(count);
    }
  }
  if (sections.length >= 3) {
    document.querySelector('aside.sidebar').classList.add('thirds');
  }
});
  </script>
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-91189608-1', 'auto');

    ga('send', 'pageview');
    </script>
</head>

<body>
  <header role="banner"><hgroup>
  <h1><a href="https://sthbrx.github.io/">Store Halfword Byte-Reverse Indexed</a></h1>
    <h2>A Power Technical Blog</h2>
</hgroup></header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="https://sthbrx.github.io/rss.xml" rel="subscribe-rss">RSS</a></li>
</ul>


<ul class="main-navigation">
      <li >
        <a href="https://sthbrx.github.io/category/development.html">Development</a>
      </li>
      <li >
        <a href="https://sthbrx.github.io/category/education.html">Education</a>
      </li>
      <li >
        <a href="https://sthbrx.github.io/category/openpower.html">OpenPOWER</a>
      </li>
      <li class="active">
        <a href="https://sthbrx.github.io/category/performance.html">Performance</a>
      </li>
      <li >
        <a href="https://sthbrx.github.io/category/petitboot.html">Petitboot</a>
      </li>
      <li >
        <a href="https://sthbrx.github.io/category/snowpatch.html">snowpatch</a>
      </li>
      <li >
        <a href="https://sthbrx.github.io/category/virtualisation-and-emulation.html">Virtualisation and Emulation</a>
      </li>
</ul></nav>
  <div id="main">
    <div id="content">
<div>
  <article class="hentry" role="article">
<header>
      <h1 class="entry-title">Get off my lawn: separating Docker workloads using cgroups</h1>
    <p class="meta">
<time datetime="2016-07-27T13:30:00+10:00" pubdate>Wed 27 July 2016</time>    </p>
</header>

  <div class="byline_index">
<p class="meta">
  <span class="byline author vcard">
    Posted by <span class="fn">
          <a href="https://sthbrx.github.io/author/daniel-axtens.html">Daniel Axtens</a>
    </span>
  </span>
<time datetime="2016-07-27T13:30:00+10:00" pubdate>Wed 27 July 2016</time>  <span class="categories">
    <a class='category' href='https://sthbrx.github.io/category/performance.html'>Performance</a>
  </span>
  <span class="categories">
    <a class="category" href="https://sthbrx.github.io/tag/cgroups.html">cgroups</a>,    <a class="category" href="https://sthbrx.github.io/tag/numa.html">numa</a>,    <a class="category" href="https://sthbrx.github.io/tag/p8.html">p8</a>  </span>
</p>  </div>
  <div class="entry-content"><p>On my team, we do two different things in our Continuous Integration setup: build/functional tests, and performance tests. Build tests simply test whether a project builds, and, if the project provides a functional test suite, that the tests pass. We do a lot of MySQL/MariaDB testing this way. The other type of testing we do is performance tests: we build a project and then run a set of benchmarks against it. Python is a good example here.</p>
<p>Build tests want as much grunt as possible. Performance tests, on the other hand, want a stable, isolated environment. Initially, we set up Jenkins so that performance and build tests never ran at the same time. Builds would get the entire machine, and performance tests would never have to share with anyone.</p>
<p>This, while simple and effective, has some downsides. In POWER land, our machines are quite beefy. For example, one of the boxes I use - an S822L - has 4 sockets, each with 4 cores. At SMT-8 (an 8 way split of each core) that gives us 4 x 4 x 8 = 128 threads. It seems wasteful to lock this entire machine - all 128 threads - just so as to isolate a single-threaded test.<sup id="fnref:1"><a class="footnote-ref" href="#fn:1">1</a></sup></p>
<p>So, <strong>can we partition our machine so that we can be running two different sorts of processes in a sufficiently isolated way?</strong></p>
<p>What counts as 'sufficiently isolated'? Well, my performance tests are CPU bound, so I want CPU isolation. I also want memory, and in particular memory bandwith to be isolated. I don't particularly care about IO isolation as my tests aren't IO heavy. Lastly, I have a couple of tests that are very multithreaded, so I'd like to have enough of a machine for those test results to be interesting.</p>
<p>For CPU isolation we have CPU affinity. We can also do something similar with memory. On a POWER8 system, memory is connected to individual P8s, not to some central point. This is a 'Non-Uniform Memory Architecture' (NUMA) setup: the directly attached memory will be very fast for a processor to access, and memory attached to other processors will be slower to access. An accessible guide (with very helpful diagrams!) is <a href="http://www.redbooks.ibm.com/redpapers/pdfs/redp5098.pdf">the relevant RedBook (PDF)</a>, chapter 2.</p>
<p>We could achieve the isolation we want by dividing up CPUs and NUMA nodes between the competing workloads. Fortunately, all of the hardware NUMA information is plumbed nicely into Linux. Each P8 socket gets a corresponding NUMA node. <code>lscpu</code> will tell you what CPUs correspond to which NUMA nodes (although what it calls a CPU we would call a hardware thread). If you install <code>numactl</code>, you can use <code>numactl -H</code> to get even more details.</p>
<p>In our case, the relevant <code>lscpu</code> output is thus:</p>
<div class="highlight"><pre><span></span><code><span class="err">NUMA node0 CPU(s):     0-31</span>
<span class="err">NUMA node1 CPU(s):     96-127</span>
<span class="err">NUMA node16 CPU(s):    32-63</span>
<span class="err">NUMA node17 CPU(s):    64-95</span>
</code></pre></div>

<p>Now all we have to do is find some way to tell Linux to restrict a group of processes to a particular NUMA node and the corresponding CPUs. How? Enter control groups, or <code>cgroups</code> for short. Processes can be put into a cgroup, and then a cgroup controller can control the resouces allocated to the cgroup. Cgroups are hierarchical, and there are controllers for a number of different ways you could control a group of processes. Most helpfully for us, there's one called <code>cpuset</code>, which can control CPU affinity, and restrict memory allocation to a NUMA node.</p>
<p>We then just have to get the processes into the relevant cgroup. Fortunately, Docker is incredibly helpful for this!<sup id="fnref:2"><a class="footnote-ref" href="#fn:2">2</a></sup> Docker containers are put in the <code>docker</code> cgroup. Each container gets it's own cgroup under the docker cgroup, and fortunately Docker deals well with the somewhat broken state of cpuset inheritance.<sup id="fnref:3"><a class="footnote-ref" href="#fn:3">3</a></sup> So it suffices to create a cpuset cgroup for docker, and allocate some resources to it, and Docker will do the rest. Here we'll allocate the last 3 sockets and NUMA nodes to Docker containers:</p>
<div class="highlight"><pre><span></span><code>cgcreate -g cpuset:docker
<span class="nb">echo</span> <span class="m">32</span>-127 &gt; /sys/fs/cgroup/cpuset/docker/cpuset.cpus
<span class="nb">echo</span> <span class="m">1</span>,16-17 &gt; /sys/fs/cgroup/cpuset/docker/cpuset.mems
<span class="nb">echo</span> <span class="m">1</span> &gt; /sys/fs/cgroup/cpuset/docker/cpuset.mem_hardwall
</code></pre></div>

<p><code>mem_hardwall</code> prevents memory allocations under docker from spilling over into the one remaining NUMA node.</p>
<p>So, does this work? I created a container with sysbench and then ran the following:</p>
<div class="highlight"><pre><span></span><code>root@0d3f339d4181:/# sysbench --test<span class="o">=</span>cpu --num-threads<span class="o">=</span><span class="m">128</span> --max-requests<span class="o">=</span><span class="m">10000000</span> run
</code></pre></div>

<p>Now I've asked for 128 threads, but the cgroup only has CPUs/hwthreads 32-127 allocated. So If I run htop, I shouldn't see any load on CPUs 0-31. What do I actually see?</p>
<p><img alt="htop screenshot, showing load only on CPUs 32-127" src="/images/dja/cgroup1.png"></p>
<p>It works! Now, we create a cgroup for performance tests using the first socket and NUMA node:</p>
<div class="highlight"><pre><span></span><code>cgcreate -g cpuset:perf-cgroup
<span class="nb">echo</span> <span class="m">0</span>-31 &gt; /sys/fs/cgroup/cpuset/perf-cgroup/cpuset.cpus
<span class="nb">echo</span> <span class="m">0</span> &gt; /sys/fs/cgroup/cpuset/perf-cgroup/cpuset.mems
<span class="nb">echo</span> <span class="m">1</span> &gt; /sys/fs/cgroup/cpuset/perf-cgroup/cpuset.mem_hardwall
</code></pre></div>

<p>Docker conveniently lets us put new containers under a different cgroup, which means we can simply do:</p>
<div class="highlight"><pre><span></span><code>dja@p88 ~&gt; docker run -it --rm --cgroup-parent<span class="o">=</span>/perf-cgroup/ ppc64le/ubuntu bash
root@b037049f94de:/# <span class="c1"># ... install sysbench</span>
root@b037049f94de:/# sysbench --test<span class="o">=</span>cpu --num-threads<span class="o">=</span><span class="m">128</span> --max-requests<span class="o">=</span><span class="m">10000000</span> run
</code></pre></div>

<p>And the result?</p>
<p><img alt="htop screenshot, showing load only on CPUs 0-31" src="/images/dja/cgroup2.png"></p>
<p>It works! My benchmark results also suggest this is sufficient isolation, and the rest of the team is happy to have more build resources to play with.</p>
<p>There are some boring loose ends to tie up: if a build job does anything outside of docker (like clone a git repo), that doesn't come under the docker cgroup, and we have to interact with systemd. Because systemd doesn't know about cpuset, this is <em>quite</em> fiddly. We also want this in a systemd unit so it runs on start up, and we want some code to tear it down. But I'll spare you the gory details.</p>
<p>In summary, cgroups are surprisingly powerful and simple to work with, especially in conjunction with Docker and NUMA on Power!</p>
<div class="footnote">
<hr>
<ol>
<li id="fn:1">
<p>It gets worse! Before the performance test starts, all the running build jobs must drain. If we have 8 Jenkins executors running on the box, and a performance test job is the next in the queue, we have to wait for 8 running jobs to clear. If they all started at different times and have different runtimes, we will inevitably spend a fair chunk of time with the machine at less than full utilisation while we're waiting.&#160;<a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
<li id="fn:2">
<p>At least, on Ubuntu 16.04. I haven't tested if this is true anywhere else.&#160;<a class="footnote-backref" href="#fnref:2" title="Jump back to footnote 2 in the text">&#8617;</a></p>
</li>
<li id="fn:3">
<p>I hear this is getting better. It is also why systemd hasn't done cpuset inheritance yet.&#160;<a class="footnote-backref" href="#fnref:3" title="Jump back to footnote 3 in the text">&#8617;</a></p>
</li>
</ol>
</div></div>
    <footer>
<div class="sharing">
</div>    </footer>
  </article>

  <section>
    <h1>Comments</h1>
    <div id="disqus_thread" aria-live="polite"><noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div>
  </section>
</div>
<aside class="sidebar">
  <section>
    <h1>Recent Posts</h1>
    <ul id="recent_posts">
      <li class="post">
          <a href="https://sthbrx.github.io/blog/2021/06/14/fuzzing-grub-part-2-going-faster/">Fuzzing grub, part 2: going faster</a>
      </li>
      <li class="post">
          <a href="https://sthbrx.github.io/blog/2021/03/04/fuzzing-grub-part-1/">Fuzzing grub: part 1</a>
      </li>
      <li class="post">
          <a href="https://sthbrx.github.io/blog/2020/01/22/linuxconfau-2020-recap/">linux.conf.au 2020 recap</a>
      </li>
      <li class="post">
          <a href="https://sthbrx.github.io/blog/2019/12/18/rfid-and-hrfid/">rfid and hrfid</a>
      </li>
      <li class="post">
          <a href="https://sthbrx.github.io/blog/2019/06/18/ten-thousand-disks/">TEN THOUSAND DISKS</a>
      </li>
    </ul>
  </section>
  <section>
      
    <h1>Categories</h1>
    <ul id="recent_posts">
        <li><a href="https://sthbrx.github.io/category/development.html">Development</a></li>
        <li><a href="https://sthbrx.github.io/category/education.html">Education</a></li>
        <li><a href="https://sthbrx.github.io/category/openpower.html">OpenPOWER</a></li>
        <li><a href="https://sthbrx.github.io/category/performance.html">Performance</a></li>
        <li><a href="https://sthbrx.github.io/category/petitboot.html">Petitboot</a></li>
        <li><a href="https://sthbrx.github.io/category/snowpatch.html">snowpatch</a></li>
        <li><a href="https://sthbrx.github.io/category/virtualisation-and-emulation.html">Virtualisation and Emulation</a></li>
    </ul>
  </section>
 

  <section>
  <h1>Tags</h1>
    <a href="https://sthbrx.github.io/tag/testing.html">testing</a>,    <a href="https://sthbrx.github.io/tag/conferences.html">conferences</a>,    <a href="https://sthbrx.github.io/tag/instruction-set-architecture.html">Instruction Set Architecture</a>,    <a href="https://sthbrx.github.io/tag/openpower.html">openpower</a>,    <a href="https://sthbrx.github.io/tag/linux.html">linux</a>,    <a href="https://sthbrx.github.io/tag/firmware.html">firmware</a>,    <a href="https://sthbrx.github.io/tag/goodposts.html">goodposts</a>,    <a href="https://sthbrx.github.io/tag/realcontent.html">realcontent</a>,    <a href="https://sthbrx.github.io/tag/madposting.html">madposting</a>,    <a href="https://sthbrx.github.io/tag/op-test.html">op-test</a>,    <a href="https://sthbrx.github.io/tag/qemu.html">qemu</a>,    <a href="https://sthbrx.github.io/tag/pci.html">pci</a>,    <a href="https://sthbrx.github.io/tag/sparseposting.html">sparseposting</a>,    <a href="https://sthbrx.github.io/tag/petitboot.html">petitboot</a>,    <a href="https://sthbrx.github.io/tag/security.html">security</a>,    <a href="https://sthbrx.github.io/tag/vscode.html">vscode</a>,    <a href="https://sthbrx.github.io/tag/code.html">code</a>,    <a href="https://sthbrx.github.io/tag/openbmc.html">openbmc</a>,    <a href="https://sthbrx.github.io/tag/ipmi.html">ipmi</a>,    <a href="https://sthbrx.github.io/tag/opencapi.html">opencapi</a>,    <a href="https://sthbrx.github.io/tag/openpower-summit.html">openpower summit</a>,    <a href="https://sthbrx.github.io/tag/easyposts.html">easyposts</a>,    <a href="https://sthbrx.github.io/tag/linuxboot.html">linuxboot</a>,    <a href="https://sthbrx.github.io/tag/google.html">google</a>,    <a href="https://sthbrx.github.io/tag/intel.html">intel</a>,    <a href="https://sthbrx.github.io/tag/osfc.html">osfc</a>,    <a href="https://sthbrx.github.io/tag/shortposts.html">shortposts</a>,    <a href="https://sthbrx.github.io/tag/facebook.html">facebook</a>,    <a href="https://sthbrx.github.io/tag/performance.html">performance</a>,    <a href="https://sthbrx.github.io/tag/phoronix.html">phoronix</a>,    <a href="https://sthbrx.github.io/tag/benchmarks.html">benchmarks</a>,    <a href="https://sthbrx.github.io/tag/kernel.html">kernel</a>,    <a href="https://sthbrx.github.io/tag/stupid-ideas.html">stupid ideas</a>,    <a href="https://sthbrx.github.io/tag/network.html">network</a>,    <a href="https://sthbrx.github.io/tag/power.html">power</a>,    <a href="https://sthbrx.github.io/tag/xdp.html">xdp</a>,    <a href="https://sthbrx.github.io/tag/networking.html">networking</a>,    <a href="https://sthbrx.github.io/tag/remoteposts.html">remoteposts</a>,    <a href="https://sthbrx.github.io/tag/ceph.html">ceph</a>,    <a href="https://sthbrx.github.io/tag/raid.html">raid</a>,    <a href="https://sthbrx.github.io/tag/storage.html">storage</a>,    <a href="https://sthbrx.github.io/tag/erasure.html">erasure</a>,    <a href="https://sthbrx.github.io/tag/lustre.html">lustre</a>,    <a href="https://sthbrx.github.io/tag/hpc.html">hpc</a>,    <a href="https://sthbrx.github.io/tag/nvlink.html">nvlink</a>,    <a href="https://sthbrx.github.io/tag/namd.html">namd</a>,    <a href="https://sthbrx.github.io/tag/cuda.html">cuda</a>,    <a href="https://sthbrx.github.io/tag/gpu.html">gpu</a>,    <a href="https://sthbrx.github.io/tag/minsky.html">minsky</a>,    <a href="https://sthbrx.github.io/tag/s822lc-for-hpc.html">S822LC for hpc</a>,    <a href="https://sthbrx.github.io/tag/debug.html">debug</a>,    <a href="https://sthbrx.github.io/tag/virtualisation.html">virtualisation</a>,    <a href="https://sthbrx.github.io/tag/dmesg.html">dmesg</a>,    <a href="https://sthbrx.github.io/tag/printk.html">printk</a>,    <a href="https://sthbrx.github.io/tag/boot.html">boot</a>,    <a href="https://sthbrx.github.io/tag/early.html">early</a>,    <a href="https://sthbrx.github.io/tag/error.html">error</a>,    <a href="https://sthbrx.github.io/tag/centos.html">centos</a>,    <a href="https://sthbrx.github.io/tag/centos7.html">centos7</a>,    <a href="https://sthbrx.github.io/tag/p8.html">p8</a>,    <a href="https://sthbrx.github.io/tag/bmc.html">bmc</a>,    <a href="https://sthbrx.github.io/tag/rhel.html">RHEL</a>,    <a href="https://sthbrx.github.io/tag/skiroot.html">skiroot</a>,    <a href="https://sthbrx.github.io/tag/devmapper.html">devmapper</a>,    <a href="https://sthbrx.github.io/tag/lvm.html">lvm</a>,    <a href="https://sthbrx.github.io/tag/cgroups.html">cgroups</a>,    <a href="https://sthbrx.github.io/tag/numa.html">numa</a>,    <a href="https://sthbrx.github.io/tag/development.html">Development</a>,    <a href="https://sthbrx.github.io/tag/netboot.html">netboot</a>,    <a href="https://sthbrx.github.io/tag/pxe.html">pxe</a>,    <a href="https://sthbrx.github.io/tag/education.html">Education</a>,    <a href="https://sthbrx.github.io/tag/work-experience.html">work experience</a>,    <a href="https://sthbrx.github.io/tag/asm.html">asm</a>,    <a href="https://sthbrx.github.io/tag/vdso.html">vdso</a>,    <a href="https://sthbrx.github.io/tag/snowpatch.html">snowpatch</a>,    <a href="https://sthbrx.github.io/tag/tools.html">tools</a>,    <a href="https://sthbrx.github.io/tag/intern.html">intern</a>,    <a href="https://sthbrx.github.io/tag/srop.html">SROP</a>,    <a href="https://sthbrx.github.io/tag/mitigation.html">mitigation</a>,    <a href="https://sthbrx.github.io/tag/double.html">double</a>,    <a href="https://sthbrx.github.io/tag/float.html">float</a>,    <a href="https://sthbrx.github.io/tag/hex.html">hex</a>,    <a href="https://sthbrx.github.io/tag/debugging.html">debugging</a>,    <a href="https://sthbrx.github.io/tag/skiboot.html">skiboot</a>,    <a href="https://sthbrx.github.io/tag/opal.html">OPAL</a>,    <a href="https://sthbrx.github.io/tag/fsp.html">FSP</a>,    <a href="https://sthbrx.github.io/tag/patches.html">patches</a>,    <a href="https://sthbrx.github.io/tag/based16.html">based16</a>,    <a href="https://sthbrx.github.io/tag/linux-gods.html">Linux Gods</a>,    <a href="https://sthbrx.github.io/tag/ozlabs.html">Ozlabs</a>,    <a href="https://sthbrx.github.io/tag/offtopic.html">offtopic</a>,    <a href="https://sthbrx.github.io/tag/autoboot.html">autoboot</a>,    <a href="https://sthbrx.github.io/tag/kexec.html">kexec</a>,    <a href="https://sthbrx.github.io/tag/aufs.html">aufs</a>,    <a href="https://sthbrx.github.io/tag/overlay.html">overlay</a>,    <a href="https://sthbrx.github.io/tag/php.html">php</a>,    <a href="https://sthbrx.github.io/tag/capi.html">capi</a>  </section>

  <section>
    <h1><a href="https://sthbrx.github.io/authors.html">Authors</a></h1>
    <ul id="authors_list">
        <li><a href="https://sthbrx.github.io/author/alastair-dsilva.html">Alastair D'Silva</a></li>
        <li><a href="https://sthbrx.github.io/author/andrew-donnellan.html">Andrew Donnellan</a></li>
        <li><a href="https://sthbrx.github.io/author/anton-blanchard.html">Anton Blanchard</a></li>
        <li><a href="https://sthbrx.github.io/author/callum-scarvell.html">Callum Scarvell</a></li>
        <li><a href="https://sthbrx.github.io/author/cyril-bur.html">Cyril Bur</a></li>
        <li><a href="https://sthbrx.github.io/author/daniel-axtens.html">Daniel Axtens</a></li>
        <li><a href="https://sthbrx.github.io/author/daniel-black.html">Daniel Black</a></li>
        <li><a href="https://sthbrx.github.io/author/joel-stanley.html">Joel Stanley</a></li>
        <li><a href="https://sthbrx.github.io/author/nick-piggin.html">Nick Piggin</a></li>
        <li><a href="https://sthbrx.github.io/author/rashmica-gupta.html">Rashmica Gupta</a></li>
        <li><a href="https://sthbrx.github.io/author/rohan-mclure.html">Rohan McLure</a></li>
        <li><a href="https://sthbrx.github.io/author/russell-currey.html">Russell Currey</a></li>
        <li><a href="https://sthbrx.github.io/author/samuel-mendoza-jonas.html">Samuel Mendoza-Jonas</a></li>
        <li><a href="https://sthbrx.github.io/author/suraj-jitindar-singh.html">Suraj Jitindar Singh</a></li>
    </ul>
  </section>


    <section>
        <h1>Social</h1>
        <ul>
            <li><a href="https://sthbrx.github.io/rss.xml" type="application/rss+xml" rel="alternate">RSS</a></li>
            <li><a href="https://github.com/sthbrx/" target="_blank">GitHub</a></li>
            <li><a href="https://lists.ozlabs.org/listinfo/linuxppc-dev" target="_blank">linuxppc mailing list</a></li>
            <li><a href="https://lists.ozlabs.org/listinfo/skiboot" target="_blank">Skiboot mailing list</a></li>
        </ul>
    </section>
    <section>
        <h1>Blogroll</h1>
        <ul>
            <li><a href="http://ozlabs.org" target="_blank">OzLabs</a></li>
        </ul>
    </section>

    <section>
        <h1>Disclaimer</h1>
        <div>
This blog represents the views of the individual authors, and doesn't necessarily represent IBM's positions, strategies or opinions.        </div>
    </section>
</aside>    </div>
  </div>
  <footer role="contentinfo"><p>
    Copyright &copy;  2015&ndash;2021  OzLabs &mdash;
  <span class="credit">Powered by <a href="http://getpelican.com">Pelican</a></span>
</p></footer>
  <script type="text/javascript">
    var disqus_shortname = 'sthbrx';
    var disqus_identifier = '/blog/2016/07/27/get-off-my-lawn-separating-docker-workloads-using-cgroups/';
    var disqus_url = 'https://sthbrx.github.io/blog/2016/07/27/get-off-my-lawn-separating-docker-workloads-using-cgroups/';
    var disqus_title = 'Get off my lawn: separating Docker workloads using cgroups';
    (function() {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = "//" + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
     })();
  </script>
</body>
</html>