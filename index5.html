<!DOCTYPE html>
<head>
  <meta charset="utf-8">
  <title>Store Halfword Byte-Reverse Indexed</title>
  <meta name="author" content="OzLabs">

  <link href="https://sthbrx.github.io/rss.xml" type="application/rss+xml" rel="alternate"
        title="Store Halfword Byte-Reverse Indexed RSS Feed" />



  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">


    <link href="https://sthbrx.github.io/favicon.png" rel="icon">

  <link href="https://sthbrx.github.io/theme/css/main.css" media="screen, projection"
        rel="stylesheet" type="text/css">

  <link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic"
        rel="stylesheet" type="text/css">
  <link href="//fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic"
        rel="stylesheet" type="text/css">

  <script type="text/javascript">
document.addEventListener('DOMContentLoaded', function() {
  var ts = document.createElement('span')
  ts.className = 'toggle-sidebar'
  ts = document.getElementById('content').appendChild(ts);
  ts.addEventListener('click', function(e) {
    e.preventDefault();
    body = document.getElementsByTagName('body')[0];
    bodyClasses = body.classList.toggle('collapse-sidebar');
  });
  var sections = document.querySelectorAll('aside.sidebar > section');
  if (sections.length > 1) {
    for (index = 0; index < sections.length; index++) {
      section = sections[index];
      if ((sections.length >= 3) && index % 3 === 0) {
        section.classList.add("first");
      }
      var count = ((index +1) % 2) ? "odd" : "even";
      section.classList.add(count);
    }
  }
  if (sections.length >= 3) {
    document.querySelector('aside.sidebar').classList.add('thirds');
  }
});
  </script>
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-91189608-1', 'auto');

    ga('send', 'pageview');
    </script>
</head>

<body>
  <header role="banner"><hgroup>
  <h1><a href="https://sthbrx.github.io/">Store Halfword Byte-Reverse Indexed</a></h1>
    <h2>A Power Technical Blog</h2>
</hgroup></header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="https://sthbrx.github.io/rss.xml" rel="subscribe-rss">RSS</a></li>
</ul>


<ul class="main-navigation">
      <li >
        <a href="https://sthbrx.github.io/category/development.html">Development</a>
      </li>
      <li >
        <a href="https://sthbrx.github.io/category/education.html">Education</a>
      </li>
      <li >
        <a href="https://sthbrx.github.io/category/openpower.html">OpenPOWER</a>
      </li>
      <li >
        <a href="https://sthbrx.github.io/category/performance.html">Performance</a>
      </li>
      <li >
        <a href="https://sthbrx.github.io/category/petitboot.html">Petitboot</a>
      </li>
      <li >
        <a href="https://sthbrx.github.io/category/snowpatch.html">snowpatch</a>
      </li>
      <li >
        <a href="https://sthbrx.github.io/category/virtualisation-and-emulation.html">Virtualisation and Emulation</a>
      </li>
</ul></nav>
  <div id="main">
    <div id="content">
<div class="blog-index">
  		<article>
<header>
      <h1 class="entry-title">
        <a href="https://sthbrx.github.io/blog/2017/03/20/erasure-coding-for-programmers-part-1/">Erasure Coding for Programmers, Part 1</a>
      </h1>
    <p class="meta">
<time datetime="2017-03-20T10:43:00+11:00" pubdate>Mon 20 March 2017</time>    </p>
</header>

<div class="byline_index">
  <span class="byline author vcard">
    Posted by <span class="fn">
          <a href="https://sthbrx.github.io/author/daniel-axtens.html">Daniel Axtens</a>
    </span>
  </span>
<time datetime="2017-03-20T10:43:00+11:00" pubdate>Mon 20 March 2017</time></div>

  <div class="entry-content"><p>Erasure coding is an increasingly popular storage technology - allowing the same level of fault tolerance as replication with a significantly reduced storage footprint.</p>
<p>Increasingly, erasure coding is available 'out of the box' on storage solutions such as Ceph and OpenStack Swift. Normally, you'd just pull in a library like <a href="https://github.com/01org/isa-l">ISA-L</a> or <a href="http://jerasure.org">jerasure</a>, and set some config options, and you'd be done.</p>
<p>This post is not about that. This post is about how I went from knowing nothing about erasure coding to writing POWER optimised routines to make it go fast. (These are in the process of being polished for upstream at the moment.) If you want to understand how erasure coding works under the hood - and in particular if you're interested in writing optimised routines to make it run quickly in your platform - this is for you.</p>
<h2>What are erasure codes anyway?</h2>
<p>I think the easiest way to begin thinking about erasure codes is "RAID 6 on steroids". RAID 6 allows you to have up to 255 data disks and 2 parity disks (called P and Q), thus allowing you to tolerate the failure of up to 2 arbitrary disks without data loss.</p>
<p>Erasure codes allow you to have k data disks and m 'parity' or coding disks. You then have a total of m + k disks, and you can tolerate the failure of up to m without losing data.</p>
<p>The downside of erasure coding is that computing what to put on those parity disks is CPU intensive. Lets look at what we put on them.</p>
<h2>RAID 6</h2>
<p>RAID 6 is the easiest way to get started on understanding erasure codes for a number of reasons. H Peter Anvin's paper on RAID 6 in the Linux kernel is an excellent start, but does dive in a bit quickly to the underlying mathematics. So before reading that, read on!</p>
<h2>Rings and Fields</h2>
<p>As programmers we're pretty comfortable with modular arithmetic - the idea that if you have:</p>
<div class="highlight"><pre><span></span><code><span class="err">unsigned char a = 255;</span>
<span class="err">a++;</span>
</code></pre></div>

<p>the new value of <code>a</code> will be 0, not 256.</p>
<p>This is an example of an algebraic structure called a <em>ring</em>.</p>
<p>Rings obey certain laws. For our purposes, we'll consider the following incomplete and somewhat simplified list:</p>
<ul>
<li>There is an addition operation.</li>
<li>There is an additive identity (normally called 0), such that 'a + 0 = a'.</li>
<li>Every element has an additive inverse, that is, for every element 'a', there is an element -a such that 'a + (-a) = 0'</li>
<li>There is a multiplication operation.</li>
<li>There is a multiplicative identity (normally called 1), such that 'a * 1 = a'.</li>
</ul>
<p>These operations aren't necessarily addition or multiplication as we might expect from the integers or real numbers. For example, in our modular arithmetic example, we have 'wrap around'. (There are also certain rules the addition and multiplication rules must satisfy - we are glossing over them here.)</p>
<p>One thing a ring doesn't have a 'multiplicative inverse'. The multiplicative inverse of some non-zero element of the ring (call it a), is the value b such that a * b = 1. (Often instead of b we write 'a^-1', but that looks bad in plain text, so we shall stick to b for now.)</p>
<p>We do have some inverses in 'mod 256': the inverse of 3 is 171 as 3 * 171 = 513, and 513 = 1 mod 256, but there is no b such that 2 * b = 1 mod 256.</p>
<p>If every non-zero element of our ring had a multiplicative inverse, we would have what is called a <em>field</em>.</p>
<p>Now, let's look at a the integers modulo 2, that is, 0 and 1.</p>
<p>We have this for addition:</p>
<table>
<thead>
<tr>
<th>+</th>
<th>0</th>
<th>1</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>0</strong></td>
<td>0</td>
<td>1</td>
</tr>
<tr>
<td><strong>1</strong></td>
<td>1</td>
<td>0</td>
</tr>
</tbody>
</table>
<p>Eagle-eyed readers will notice that this is the same as XOR.</p>
<p>For multiplication: </p>
<table>
<thead>
<tr>
<th>*</th>
<th>0</th>
<th>1</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>0</strong></td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td><strong>1</strong></td>
<td>0</td>
<td>1</td>
</tr>
</tbody>
</table>
<p>As we said, a field is a ring where every non-zero element has a multiplicative inverse. As we can see, the integers modulo 2 shown above is a field: it's a ring, and 1 is its own multiplicative inverse.</p>
<p>So this is all well and good, but you can't really do very much in a field with 2 elements. This is sad, so we make bigger fields. For this application, we consider the Galois Field with 256 elements - GF(2^8). This field has some surprising and useful properties.</p>
<p>Remember how we said that integers modulo 256 weren't a field because they didn't have multiplicative inverses? I also just said that GF(2^8) also has 256 elements, but is a field - i.e., it does have inverses! How does that work?</p>
<p>Consider an element in GF(2^8). There are 2 ways to look at an element in GF(2^8). The first is to consider it as an 8-bit number. So, for example, let's take 100. We can express that as as an 8 bit binary number: 0b01100100.</p>
<p>We can write that more explicitly as a sum of powers of 2:</p>
<div class="highlight"><pre><span></span><code><span class="err">0 * 2^7 + 1 * 2^6 + 1 * 2^5 + 0 * 2^4 + 0 * 2^3 + 1 * 2^2 + 0 * 2 + 0 * 1</span>
<span class="err">= 2^6 + 2^5 + 2^2</span>
</code></pre></div>

<p>Now the other way we can look at elements in GF(2^8) is to replace the '2's with 'x's, and consider them as polynomials. Each of our bits then represents the coefficient of a term of a polynomial, that is:</p>
<div class="highlight"><pre><span></span><code><span class="err">0 x^7 + 1 x^6 + 1 x^5 + 0 x^4 + 0 x^3 + 1 x^2 + 0 x + 0 * 1</span>
</code></pre></div>

<p>or more simply</p>
<div class="highlight"><pre><span></span><code><span class="err">x^6 + x^5 + x^2</span>
</code></pre></div>

<p>Now, and this is <strong>important</strong>: each of the coefficients are elements of the integers modulo 2: x + x = 2x = 0 as 2 mod 2 = 0. There is no concept of 'carrying' in this addition.</p>
<p>Let's try: what's 100 + 79 in GF(2^8)?</p>
<div class="highlight"><pre><span></span><code><span class="mi">100</span> <span class="o">=</span> <span class="mi">0</span><span class="n">b01100100</span> <span class="o">=&gt;</span> <span class="n">x</span><span class="o">^</span><span class="mi">6</span> <span class="o">+</span> <span class="n">x</span><span class="o">^</span><span class="mi">5</span> <span class="o">+</span>       <span class="n">x</span><span class="o">^</span><span class="mi">2</span>
 <span class="mi">79</span> <span class="o">=</span> <span class="mi">0</span><span class="n">b01001111</span> <span class="o">=&gt;</span> <span class="n">x</span><span class="o">^</span><span class="mi">6</span> <span class="o">+</span>       <span class="n">x</span><span class="o">^</span><span class="mi">3</span> <span class="o">+</span> <span class="n">x</span><span class="o">^</span><span class="mi">2</span> <span class="o">+</span> <span class="n">x</span> <span class="o">+</span> <span class="mi">1</span>

<span class="mi">100</span> <span class="o">+</span> <span class="mi">79</span>         <span class="o">=&gt;</span>   <span class="mi">0</span> <span class="o">+</span> <span class="n">x</span><span class="o">^</span><span class="mi">5</span> <span class="o">+</span> <span class="n">x</span><span class="o">^</span><span class="mi">3</span> <span class="o">+</span>   <span class="mi">0</span> <span class="o">+</span> <span class="n">x</span> <span class="o">+</span> <span class="mi">1</span>
                 <span class="o">=</span>    <span class="mi">0</span><span class="n">b00101011</span> <span class="o">=</span> <span class="mi">43</span>
</code></pre></div>

<p>So, 100 + 79 = 43 in GF(2^8)</p>
<p>You may notice we could have done that much more efficiently: we can add numbers in GF(2^8) by just XORing their binary representations together. Subtraction, amusingly, is the same as addition: 0 + x = x =  0 - x, as -1 is congruent to 1 modulo 2.</p>
<p>So at this point you might be wanting to explore a few additions yourself. Fortuantely there's a lovely tool that will allow you to do that:</p>
<div class="highlight"><pre><span></span><code><span class="n">sudo</span> <span class="n">apt</span> <span class="n">install</span> <span class="n">gf</span><span class="o">-</span><span class="n">complete</span><span class="o">-</span><span class="n">tools</span>
<span class="n">gf_add</span> <span class="o">$</span><span class="n">A</span> <span class="o">$</span><span class="n">B</span> <span class="mi">8</span>
</code></pre></div>

<p>This will give you A + B in GF(2^8).</p>
<div class="highlight"><pre><span></span><code><span class="err">&gt; gf_add 100 79 8</span>
<span class="err">43</span>
</code></pre></div>

<p>Excellent!</p>
<p>So, hold on to your hats, as this is where things get really weird. In modular arithmetic example, we considered the elements of our ring to be numbers, and we performed our addition and multiplication modulo 256. In GF(2^8), we consider our elements as polynomials and we perform our addition and multiplication modulo a polynomial. There is one conventional polynomial used in applications:</p>
<div class="highlight"><pre><span></span><code><span class="err">0x11d =&gt; 0b1 0001 1101 =&gt; x^8 + x^4 + x^3 + x^2 + 1</span>
</code></pre></div>

<p>It is possible to use other polynomials if they satisfy particular requirements, but for our applications we don't need to worry as we will always use 0x11d. I am not going to attempt to explain anything about this polynomial - take it as an article of faith.</p>
<p>So when we multiply two numbers, we multiply their polynomial representations. Then, to find out what that is modulo 0x11d, we do polynomial long division by 0x11d, and take the remainder.</p>
<p>Some examples will help.</p>
<p>Let's multiply 100 by 3.</p>
<div class="highlight"><pre><span></span><code><span class="mi">100</span> <span class="o">=</span> <span class="mi">0</span><span class="n">b01100100</span> <span class="o">=&gt;</span> <span class="n">x</span><span class="o">^</span><span class="mi">6</span> <span class="o">+</span> <span class="n">x</span><span class="o">^</span><span class="mi">5</span> <span class="o">+</span> <span class="n">x</span><span class="o">^</span><span class="mi">2</span>
  <span class="mi">3</span> <span class="o">=</span> <span class="mi">0</span><span class="n">b00000011</span> <span class="o">=&gt;</span> <span class="n">x</span> <span class="o">+</span> <span class="mi">1</span>

<span class="p">(</span><span class="n">x</span><span class="o">^</span><span class="mi">6</span> <span class="o">+</span> <span class="n">x</span><span class="o">^</span><span class="mi">5</span> <span class="o">+</span> <span class="n">x</span><span class="o">^</span><span class="mi">2</span><span class="p">)(</span><span class="n">x</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">=</span> <span class="n">x</span><span class="o">^</span><span class="mi">7</span> <span class="o">+</span> <span class="n">x</span><span class="o">^</span><span class="mi">6</span> <span class="o">+</span> <span class="n">x</span><span class="o">^</span><span class="mi">3</span> <span class="o">+</span> <span class="n">x</span><span class="o">^</span><span class="mi">6</span> <span class="o">+</span> <span class="n">x</span><span class="o">^</span><span class="mi">5</span> <span class="o">+</span> <span class="n">x</span><span class="o">^</span><span class="mi">2</span>
                         <span class="o">=</span> <span class="n">x</span><span class="o">^</span><span class="mi">7</span> <span class="o">+</span> <span class="n">x</span><span class="o">^</span><span class="mi">5</span> <span class="o">+</span> <span class="n">x</span><span class="o">^</span><span class="mi">3</span> <span class="o">+</span> <span class="n">x</span><span class="o">^</span><span class="mi">2</span>
</code></pre></div>

<p>Notice that some of the terms have disappeared: x^6 + x^6 = 0.</p>
<p>The degree (the largest power of a term) is 7. 7 is less than the degree of 0x11d, which is 8, so we don't need to do anything: the remainder modulo 0x11d is simply x^7 + x^5 + x^3 + x^2.</p>
<p>In binary form, that is 0b10101100 = 172, so 100 * 3 = 172 in GF(2^8).</p>
<p>Fortunately <code>gf-complete-tools</code> also allows us to check multiplications:</p>
<div class="highlight"><pre><span></span><code><span class="err">&gt; gf_mult 100 3 8</span>
<span class="err">172</span>
</code></pre></div>

<p>Excellent!</p>
<p>Now let's see what happens if we multiply by a larger number. Let's multiply 100 by 5.</p>
<div class="highlight"><pre><span></span><code><span class="mi">100</span> <span class="o">=</span> <span class="mi">0</span><span class="n">b01100100</span> <span class="o">=&gt;</span> <span class="n">x</span><span class="o">^</span><span class="mi">6</span> <span class="o">+</span> <span class="n">x</span><span class="o">^</span><span class="mi">5</span> <span class="o">+</span> <span class="n">x</span><span class="o">^</span><span class="mi">2</span>
  <span class="mi">5</span> <span class="o">=</span> <span class="mi">0</span><span class="n">b00000101</span> <span class="o">=&gt;</span> <span class="n">x</span><span class="o">^</span><span class="mi">2</span> <span class="o">+</span> <span class="mi">1</span>

<span class="p">(</span><span class="n">x</span><span class="o">^</span><span class="mi">6</span> <span class="o">+</span> <span class="n">x</span><span class="o">^</span><span class="mi">5</span> <span class="o">+</span> <span class="n">x</span><span class="o">^</span><span class="mi">2</span><span class="p">)(</span><span class="n">x</span><span class="o">^</span><span class="mi">2</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">=</span> <span class="n">x</span><span class="o">^</span><span class="mi">8</span> <span class="o">+</span> <span class="n">x</span><span class="o">^</span><span class="mi">7</span> <span class="o">+</span> <span class="n">x</span><span class="o">^</span><span class="mi">4</span> <span class="o">+</span> <span class="n">x</span><span class="o">^</span><span class="mi">6</span> <span class="o">+</span> <span class="n">x</span><span class="o">^</span><span class="mi">5</span> <span class="o">+</span> <span class="n">x</span><span class="o">^</span><span class="mi">2</span>
                           <span class="o">=</span> <span class="n">x</span><span class="o">^</span><span class="mi">8</span> <span class="o">+</span> <span class="n">x</span><span class="o">^</span><span class="mi">7</span> <span class="o">+</span> <span class="n">x</span><span class="o">^</span><span class="mi">6</span> <span class="o">+</span> <span class="n">x</span><span class="o">^</span><span class="mi">5</span> <span class="o">+</span> <span class="n">x</span><span class="o">^</span><span class="mi">4</span> <span class="o">+</span> <span class="n">x</span><span class="o">^</span><span class="mi">2</span>
</code></pre></div>

<p>Here we have an x^8 term, so we have a degree of 8. This means will get a different remainder when we divide by our polynomial. We do this with polynomial long division, which you will hopefully remember if you did some solid algebra in high school.</p>
<div class="highlight"><pre><span></span><code><span class="err">                              1</span>
<span class="err">                           ---------------------------------------------</span>
<span class="err">x^8 + x^4 + x^3 + x^2 + 1 | x^8 + x^7 + x^6 + x^5 + x^4       + x^2</span>
<span class="err">                          - x^8                   + x^4 + x^3 + x^2 + 1</span>
<span class="err">                            -------------------------------------------</span>
<span class="err">                          =       x^7 + x^6 + x^5       + x^3       + 1</span>
</code></pre></div>

<p>So we have that our original polynomial (x^8 + x^4 + x^3 + x^2 + 1) is congruent to (x^7 + x^6 + x^5 + x^3 + 1) modulo the polynomial 0x11d.
Looking at the binary representation of that new polynomial, we have 0b11101001 = 233.</p>
<p>Sure enough:</p>
<div class="highlight"><pre><span></span><code><span class="err">&gt; gf_mult 100 5 8</span>
<span class="err">233</span>
</code></pre></div>

<p>Just to solidify the polynomial long division a bit, let's try a slightly larger example, 100 * 9:</p>
<div class="highlight"><pre><span></span><code><span class="mi">100</span> <span class="o">=</span> <span class="mi">0</span><span class="n">b01100100</span> <span class="o">=&gt;</span> <span class="n">x</span><span class="o">^</span><span class="mi">6</span> <span class="o">+</span> <span class="n">x</span><span class="o">^</span><span class="mi">5</span> <span class="o">+</span> <span class="n">x</span><span class="o">^</span><span class="mi">2</span>
  <span class="mi">9</span> <span class="o">=</span> <span class="mi">0</span><span class="n">b00001001</span> <span class="o">=&gt;</span> <span class="n">x</span><span class="o">^</span><span class="mi">3</span> <span class="o">+</span> <span class="mi">1</span>

<span class="p">(</span><span class="n">x</span><span class="o">^</span><span class="mi">6</span> <span class="o">+</span> <span class="n">x</span><span class="o">^</span><span class="mi">5</span> <span class="o">+</span> <span class="n">x</span><span class="o">^</span><span class="mi">2</span><span class="p">)(</span><span class="n">x</span><span class="o">^</span><span class="mi">3</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">=</span> <span class="n">x</span><span class="o">^</span><span class="mi">9</span> <span class="o">+</span> <span class="n">x</span><span class="o">^</span><span class="mi">8</span> <span class="o">+</span> <span class="n">x</span><span class="o">^</span><span class="mi">5</span> <span class="o">+</span> <span class="n">x</span><span class="o">^</span><span class="mi">6</span> <span class="o">+</span> <span class="n">x</span><span class="o">^</span><span class="mi">5</span> <span class="o">+</span> <span class="n">x</span><span class="o">^</span><span class="mi">2</span>
                           <span class="o">=</span> <span class="n">x</span><span class="o">^</span><span class="mi">9</span> <span class="o">+</span> <span class="n">x</span><span class="o">^</span><span class="mi">8</span> <span class="o">+</span> <span class="n">x</span><span class="o">^</span><span class="mi">6</span> <span class="o">+</span> <span class="n">x</span><span class="o">^</span><span class="mi">2</span>
</code></pre></div>

<p>Doing long division to reduce our result:</p>
<div class="highlight"><pre><span></span><code><span class="err">                              x</span>
<span class="err">                           -----------------------------------</span>
<span class="err">x^8 + x^4 + x^3 + x^2 + 1 | x^9 + x^8       + x^6                   + x^2</span>
<span class="err">                          - x^9                   + x^5 + x^4 + x^3       + x</span>
<span class="err">                            -------------------------------------------------</span>
<span class="err">                          =       x^8       + x^6 + x^5 + x^4 + x^3 + x^2 + x</span>
</code></pre></div>

<p>We still have a polynomial of degree 8, so we can do another step:</p>
<div class="highlight"><pre><span></span><code><span class="err">                              x +   1</span>
<span class="err">                           -----------------------------------</span>
<span class="err">x^8 + x^4 + x^3 + x^2 + 1 | x^9 + x^8       + x^6                   + x^2</span>
<span class="err">                          - x^9                   + x^5 + x^4 + x^3       + x</span>
<span class="err">                            -------------------------------------------------</span>
<span class="err">                          =       x^8       + x^6 + x^5 + x^4 + x^3 + x^2 + x</span>
<span class="err">                          -       x^8                   + x^4 + x^3 + x^2     + 1</span>
<span class="err">                                  -----------------------------------------------</span>
<span class="err">                          =                   x^6 + x^5                   + x + 1</span>
</code></pre></div>

<p>We now have a polynomial of degree less than 8 that is congruent to our original polynomial modulo 0x11d, and the binary form is 0x01100011 = 99.</p>
<div class="highlight"><pre><span></span><code><span class="err">&gt; gf_mult 100 9 8</span>
<span class="err">99</span>
</code></pre></div>

<p>This process can be done more efficiently, of course - but understanding what is going on will make you <em>much</em> more comfortable with what is going on!</p>
<p>I will not try to convince you that all multiplicative inverses exist in this magic shadow land of GF(2^8), but it's important for the rest of the algorithms to work that they do exist. Trust me on this.</p>
<h2>Back to RAID 6</h2>
<p>Equipped with this knowledge, you are ready to take on <a href="https://www.kernel.org/pub/linux/kernel/people/hpa/raid6.pdf">RAID6 in the kernel</a> (PDF) sections 1 - 2.</p>
<p>Pause when you get to section 3 - this snippet is a bit magic and benefits from some explanation:</p>
<blockquote>
<p>Multiplication by {02} for a single byte can be implemeted using the C code:</p>
</blockquote>
<div class="highlight"><pre><span></span><code><span class="err">uint8_t c, cc;</span>
<span class="err">cc = (c &lt;&lt; 1) ^ ((c &amp; 0x80) ? 0x1d : 0);</span>
</code></pre></div>

<p>How does this work? Well:</p>
<p>Say you have a binary number 0bNMMM MMMM. Mutiplication by 2 gives you 0bNMMMMMMM0, which is 9 bits. Now, there are two cases to consider.</p>
<p>If your leading bit (N) is 0, your product doesn't have an x^8 term, so we don't need to reduce it modulo the irreducible polynomial.</p>
<p>If your leading bit is 1 however, your product is x^8 + something, which does need to be reduced. Fortunately, because we took an 8 bit number and multiplied it by 2, the largest term is x^8, so we only need to reduce it once. So we xor our number with our polynomial to subtract it.</p>
<p>We implement this by letting the top bit overflow out and then xoring the lower 8 bits with the low 8 bits of the polynomial (0x1d)</p>
<p>So, back to the original statement:</p>
<div class="highlight"><pre><span></span><code><span class="err">(c &lt;&lt; 1) ^ ((c &amp; 0x80) ? 0x1d : 0)</span>
<span class="err">    |          |          |     |</span>
<span class="err">    &gt; multiply by 2       |     |</span>
<span class="err">               |          |     |</span>
<span class="err">               &gt; is the high bit set - will the product have an x^8 term?</span>
<span class="err">                          |     |</span>
<span class="err">                          &gt; if so, reduce by the polynomial</span>
<span class="err">                                |</span>
<span class="err">                                &gt; otherwise, leave alone</span>
</code></pre></div>

<p>Hopefully that makes sense.</p>
<h3>Key points</h3>
<p>It's critical you understand the section on Altivec (the vperm stuff), so let's cover it in a bit more detail.</p>
<p>Say you want to do A * V, where A is a constant and V is an 8-bit variable. We can express V as V_a + V_b, where V_a is the top 4 bits of V, and V_b is the bottom 4 bits. A * V = A * V_a + A * V_b</p>
<p>We can then make lookup tables for multiplication by A.</p>
<p>If we did this in the most obvious way, we would need a 256 entry lookup table. But by splitting things into the top and bottom halves, we can reduce that to two 16 entry tables. For example, say A = 02.</p>
<table>
<thead>
<tr>
<th>V_a</th>
<th>A * V_a</th>
</tr>
</thead>
<tbody>
<tr>
<td>00</td>
<td>00</td>
</tr>
<tr>
<td>01</td>
<td>02</td>
</tr>
<tr>
<td>02</td>
<td>04</td>
</tr>
<tr>
<td>...</td>
<td>...</td>
</tr>
<tr>
<td>0f</td>
<td>1e</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th>V_b</th>
<th>A * V_b</th>
</tr>
</thead>
<tbody>
<tr>
<td>00</td>
<td>00</td>
</tr>
<tr>
<td>10</td>
<td>20</td>
</tr>
<tr>
<td>20</td>
<td>40</td>
</tr>
<tr>
<td>...</td>
<td>...</td>
</tr>
<tr>
<td>f0</td>
<td>fd</td>
</tr>
</tbody>
</table>
<p>We then use vperm to look up entries in these tables and vxor to combine our results.</p>
<p>So - and this is a key point - for each A value we wish to multiply by, we need to generate a new lookup table.</p>
<p>So if we wanted A = 03:</p>
<table>
<thead>
<tr>
<th>V_a</th>
<th>A * V_a</th>
</tr>
</thead>
<tbody>
<tr>
<td>00</td>
<td>00</td>
</tr>
<tr>
<td>01</td>
<td>03</td>
</tr>
<tr>
<td>02</td>
<td>06</td>
</tr>
<tr>
<td>...</td>
<td>...</td>
</tr>
<tr>
<td>0f</td>
<td>11</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th>V_b</th>
<th>A * V_b</th>
</tr>
</thead>
<tbody>
<tr>
<td>00</td>
<td>00</td>
</tr>
<tr>
<td>10</td>
<td>30</td>
</tr>
<tr>
<td>20</td>
<td>60</td>
</tr>
<tr>
<td>...</td>
<td>...</td>
</tr>
<tr>
<td>f0</td>
<td>0d</td>
</tr>
</tbody>
</table>
<p>One final thing is that Power8 adds a vpermxor instruction, so we can reduce the entire 4 instruction sequence in the paper:</p>
<div class="highlight"><pre><span></span><code><span class="err">vsrb v1, v0, v14</span>
<span class="err">vperm v2, v12, v12, v0</span>
<span class="err">vperm v1, v13, v13, v1</span>
<span class="err">vxor v1, v2, v1</span>
</code></pre></div>

<p>to 1 vpermxor:</p>
<div class="highlight"><pre><span></span><code><span class="err">vpermxor v1, v12, v13, v0</span>
</code></pre></div>

<p>Isn't POWER grand?</p>
<h2>OK, but how does this relate to erasure codes?</h2>
<p>I'm glad you asked.</p>
<p>Galois Field arithmetic, and its application in RAID 6 is the basis for erasure coding. (It's also the basis for CRCs - two for the price of one!)</p>
<p>But, that's all to come in part 2, which will definitely be published before 7 April!</p>
<p>Many thanks to Sarah Axtens who reviewed the mathematical content of this post and suggested significant improvements. All errors and gross oversimplifications remain my own. Thanks also to the OzLabs crew for their feedback and comments.</p></div>
  		</article>
  		<article>
<header>
      <h1 class="entry-title">
        <a href="https://sthbrx.github.io/blog/2017/02/13/high-power-lustre/">High Power Lustre</a>
      </h1>
    <p class="meta">
<time datetime="2017-02-13T16:29:00+11:00" pubdate>Mon 13 February 2017</time>    </p>
</header>

<div class="byline_index">
  <span class="byline author vcard">
    Posted by <span class="fn">
          <a href="https://sthbrx.github.io/author/daniel-axtens.html">Daniel Axtens</a>,
          <a href="https://sthbrx.github.io/author/rashmica-gupta.html">Rashmica Gupta</a>
    </span>
  </span>
<time datetime="2017-02-13T16:29:00+11:00" pubdate>Mon 13 February 2017</time></div>

  <div class="entry-content"><p>(Most of the hard work here was done by fellow blogger Rashmica - I just verified her instructions and wrote up this post.)</p>
<p><a href="http://lustre.org/">Lustre</a> is a high-performance clustered file system. Traditionally the Lustre client and server have run on x86, but both the server and client will also work on Power. Here's how to get them running.</p>
<h1>Server</h1>
<p>Lustre normally requires a patched 'enterprise' kernel - normally an old RHEL, CentOS or SUSE kernel. We tested with a CentOS 7.3 kernel. We tried to follow <a href="https://wiki.hpdd.intel.com/pages/viewpage.action?pageId=52104622">the Intel instructions</a> for building the kernel as much as possible - any deviations we had to make are listed below.</p>
<h2>Setup quirks</h2>
<p>We are told to edit <code>~/kernel/rpmbuild/SPEC/kernel.spec</code>. This doesn't exist because the directory is <code>SPECS</code> not <code>SPEC</code>: you need to edit <code>~/kernel/rpmbuild/SPECS/kernel.spec</code>.</p>
<p>I also found there was an extra quote mark in the supplied patch script after <code>-lustre.patch</code>. I removed that and ran this instead:</p>
<div class="highlight"><pre><span></span><code>for patch in $(<span class="err">&lt;</span>&quot;3.10-rhel7.series&quot;); do \
      patch_file=&quot;<span class="nv">$HOME</span>/lustre-release/lustre/kernel_patches/patches/<span class="cp">${</span><span class="n">patch</span><span class="cp">}</span>&quot; \
      cat &quot;<span class="cp">${</span><span class="n">patch_file</span><span class="cp">}</span>&quot; &gt;&gt; <span class="nv">$HOME</span>/lustre-kernel-x86_64-lustre.patch \
done
</code></pre></div>

<p>The fact that there is 'x86_64' in the patch name doesn't matter as you're about to copy it under a different name to a place where it will be included by the spec file.</p>
<h2>Building for ppc64le</h2>
<p>Building for ppc64le was reasonably straight-forward. I had one small issue:</p>
<div class="highlight"><pre><span></span><code><span class="p">[</span><span class="n">build</span><span class="err">@</span><span class="n">dja</span><span class="o">-</span><span class="n">centos</span><span class="o">-</span><span class="n">guest</span> <span class="n">rpmbuild</span><span class="p">]</span><span class="o">$</span> <span class="n">rpmbuild</span> <span class="o">-</span><span class="n">bp</span> <span class="o">--</span><span class="n">target</span><span class="o">=</span><span class="err">`</span><span class="n">uname</span> <span class="o">-</span><span class="n">m</span><span class="err">`</span> <span class="o">./</span><span class="n">SPECS</span><span class="o">/</span><span class="n">kernel</span><span class="o">.</span><span class="n">spec</span>
<span class="n">Building</span> <span class="n">target</span> <span class="n">platforms</span><span class="p">:</span> <span class="n">ppc64le</span>
<span class="n">Building</span> <span class="k">for</span> <span class="n">target</span> <span class="n">ppc64le</span>
<span class="n">error</span><span class="p">:</span> <span class="n">Failed</span> <span class="n">build</span> <span class="n">dependencies</span><span class="p">:</span>
       <span class="n">net</span><span class="o">-</span><span class="n">tools</span> <span class="k">is</span> <span class="n">needed</span> <span class="n">by</span> <span class="n">kernel</span><span class="o">-</span><span class="mf">3.10</span><span class="o">.</span><span class="mi">0</span><span class="o">-</span><span class="mf">327.36</span><span class="o">.</span><span class="mf">3.</span><span class="n">el7</span><span class="o">.</span><span class="n">ppc64le</span>
</code></pre></div>

<p>Fixing this was as simple as a <code>yum install net-tools</code>.</p>
<p>This was sufficient to build the kernel RPMs. I installed them and booted to my patched kernel - so far so good!</p>
<h1>Building the client packages: CentOS</h1>
<p>I then tried to build and install the RPMs from <a href="https://git.hpdd.intel.com/?p=fs/lustre-release.git;a=summary"><code>lustre-release</code></a>. This repository provides the sources required to build the client and utility binaries.</p>
<p><code>./configure</code> and <code>make</code> succeeded, but when I went to install the packages with <code>rpm</code>, I found I was missing some dependencies:</p>
<div class="highlight"><pre><span></span><code><span class="n">error</span><span class="o">:</span> <span class="n">Failed</span> <span class="n">dependencies</span><span class="o">:</span>
        <span class="n">ldiskfsprogs</span> <span class="o">&gt;=</span> <span class="mf">1.42</span><span class="o">.</span><span class="mi">7</span><span class="o">.</span><span class="na">wc1</span> <span class="k">is</span> <span class="n">needed</span> <span class="n">by</span> <span class="n">kmod</span><span class="o">-</span><span class="n">lustre</span><span class="o">-</span><span class="n">osd</span><span class="o">-</span><span class="n">ldiskfs</span><span class="o">-</span><span class="mf">2.9</span><span class="o">.</span><span class="mi">52</span><span class="n">_60_g1d2fbad_dirty</span><span class="o">-</span><span class="mi">1</span><span class="o">.</span><span class="na">el7</span><span class="o">.</span><span class="na">centos</span><span class="o">.</span><span class="na">ppc64le</span>
    <span class="n">sg3_utils</span> <span class="k">is</span> <span class="n">needed</span> <span class="n">by</span> <span class="n">lustre</span><span class="o">-</span><span class="n">iokit</span><span class="o">-</span><span class="mf">2.9</span><span class="o">.</span><span class="mi">52</span><span class="n">_60_g1d2fbad_dirty</span><span class="o">-</span><span class="mi">1</span><span class="o">.</span><span class="na">el7</span><span class="o">.</span><span class="na">centos</span><span class="o">.</span><span class="na">ppc64le</span>
        <span class="n">attr</span> <span class="k">is</span> <span class="n">needed</span> <span class="n">by</span> <span class="n">lustre</span><span class="o">-</span><span class="n">tests</span><span class="o">-</span><span class="mf">2.9</span><span class="o">.</span><span class="mi">52</span><span class="n">_60_g1d2fbad_dirty</span><span class="o">-</span><span class="mi">1</span><span class="o">.</span><span class="na">el7</span><span class="o">.</span><span class="na">centos</span><span class="o">.</span><span class="na">ppc64le</span>
        <span class="n">lsof</span> <span class="k">is</span> <span class="n">needed</span> <span class="n">by</span> <span class="n">lustre</span><span class="o">-</span><span class="n">tests</span><span class="o">-</span><span class="mf">2.9</span><span class="o">.</span><span class="mi">52</span><span class="n">_60_g1d2fbad_dirty</span><span class="o">-</span><span class="mi">1</span><span class="o">.</span><span class="na">el7</span><span class="o">.</span><span class="na">centos</span><span class="o">.</span><span class="na">ppc64le</span>
</code></pre></div>

<p>I was able to install <code>sg3_utils</code>, <code>attr</code> and <code>lsof</code>, but I was still missing <code>ldiskfsprogs</code>.</p>
<p>It seems we need the lustre-patched version of <code>e2fsprogs</code> - I found a <a href="https://groups.google.com/forum/#!topic/lustre-discuss-list/U93Ja6Xkxfk">mailing list post</a> to that effect.</p>
<p>So, following the instructions on the walkthrough, I grabbed <a href="https://downloads.hpdd.intel.com/public/e2fsprogs/latest/el7/SRPMS/">the SRPM</a> and installed the dependencies: <code>yum install -y texinfo libblkid-devel libuuid-devel</code></p>
<p>I then tried <code>rpmbuild -ba SPECS/e2fsprogs-RHEL-7.spec</code>. This built but failed tests. Some failed because I ran out of disk space - they were using 10s of gigabytes. I found that there were some comments in the spec file about this with suggested tests to disable, so I did that. Even with that fix, I was still failing two tests:</p>
<ul>
<li><code>f_pgsize_gt_blksize</code>: Intel added this to their fork, and no equivalent exists in the master e2fsprogs branches. This relates to Intel specific assumptions about page sizes which don't hold on Power.</li>
<li><code>f_eofblocks</code>: This may need fixing for large page sizes, see <a href="https://jira.hpdd.intel.com/browse/LU-4677?focusedCommentId=78814&amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-78814">this bug</a>.</li>
</ul>
<p>I disabled the tests by adding the following two lines to the spec file, just before <code>make %{?_smp_mflags} check</code>.</p>
<div class="highlight"><pre><span></span><code><span class="err">rm -rf tests/f_pgsize_gt_blksize</span>
<span class="err">rm -rf tests/f_eofblocks</span>
</code></pre></div>

<p>With those tests disabled I was able to build the packages successfully. I installed them with <code>yum localinstall *1.42.13.wc5*</code> (I needed that rather weird pattern to pick up important RPMs that didn't fit the <code>e2fs*</code> pattern - things like <code>libcom_err</code> and <code>libss</code>)</p>
<p>Following that I went back to the <code>lustre-release</code> build products and was able to successfully run <code>yum localinstall *ppc64le.rpm</code>!</p>
<h1>Testing the server</h1>
<p>After disabling SELinux and rebooting, I ran the test script:</p>
<div class="highlight"><pre><span></span><code><span class="err">sudo /usr/lib64/lustre/tests/llmount.sh</span>
</code></pre></div>

<p>This spat out one scary warning:</p>
<div class="highlight"><pre><span></span><code><span class="n">mount</span><span class="o">.</span><span class="n">lustre</span> <span class="n">FATAL</span><span class="p">:</span> <span class="n">unhandled</span><span class="o">/</span><span class="n">unloaded</span> <span class="n">fs</span> <span class="n">type</span> <span class="mi">0</span> <span class="s1">&#39;ext3&#39;</span>
</code></pre></div>

<p>The test did seem to succeed overall, and it would seem that is a <a href="https://jira.hpdd.intel.com/browse/LU-9059">known problem</a>, so I pressed on undeterred.</p>
<p>I then attached a couple of virtual harddrives for the metadata and object store volumes, and having set them up, proceeded to try to mount my freshly minted lustre volume from some clients.</p>
<h1>Testing with a ppc64le client</h1>
<p>My first step was to test whether another ppc64le machine would work as a client.</p>
<p>I tried with an existing Ubuntu 16.04 VM that I use for much of my day to day development.</p>
<p>A quick google suggested that I could grab the <code>lustre-release</code> repository and run <code>make debs</code> to get Debian packages for my system.</p>
<p>I needed the following dependencies:</p>
<div class="highlight"><pre><span></span><code><span class="err">sudo apt install module-assistant debhelper dpatch libsnmp-dev quilt</span>
</code></pre></div>

<p>With those the packages built successfully, and could be easily installed:</p>
<div class="highlight"><pre><span></span><code><span class="err">dpkg -i lustre-client-modules-4.4.0-57-generic_2.9.52-60-g1d2fbad-dirty-1_ppc64el.deblustre-utils_2.9.52-60-g1d2fbad-dirty-1_ppc64el.deb</span>
</code></pre></div>

<p>I tried to connect to the server:</p>
<div class="highlight"><pre><span></span><code><span class="err">sudo mount -t lustre $SERVER_IP@tcp:/lustre /lustre/</span>
</code></pre></div>

<p>Initially I wasn't able to connect to the server at all. I remembered that (unlike Ubuntu), CentOS comes with quite an aggressive firewall by default. I ran the following on the server:</p>
<div class="highlight"><pre><span></span><code><span class="err">systemctl stop firewalld</span>
</code></pre></div>

<p>And voila! I was able to connect, mount the lustre volume, and successfully read and write to it. This is very much an over-the-top hack - I should have poked holes in the firewall to allow just the ports lustre needed. This is left as an exercise for the reader.</p>
<h1>Testing with an x86_64 client</h1>
<p>I then tried to run <code>make debs</code> on my Ubuntu 16.10 x86_64 laptop.</p>
<p>This did not go well - I got the following error:</p>
<div class="highlight"><pre><span></span><code><span class="err">liblustreapi.c: In function ‘llapi_get_poollist’:</span>
<span class="err">liblustreapi.c:1201:3: error: ‘readdir_r’ is deprecated [-Werror=deprecated-declarations]</span>
</code></pre></div>

<p>This looks like one of the new errors introduced in recent GCC versions, and is <a href="https://jira.hpdd.intel.com/browse/LU-8724?focusedCommentId=175244&amp;page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#comment-175244">a known bug</a>. To work around it, I found the following stanza in a <code>lustre/autoconf/lustre-core.m4</code>, and removed the <code>-Werror</code>:</p>
<div class="highlight"><pre><span></span><code><span class="err">AS_IF([test $target_cpu == &quot;i686&quot; -o $target_cpu == &quot;x86_64&quot;],</span>
<span class="err">        [CFLAGS=&quot;$CFLAGS -Wall -Werror&quot;])</span>
</code></pre></div>

<p>Even this wasn't enough: I got the following errors:</p>
<div class="highlight"><pre><span></span><code><span class="err">/home/dja/dev/lustre-release/debian/tmp/modules-deb/usr_src/modules/lustre/lustre/llite/dcache.c:387:22: error: initialization from incompatible pointer type [-Werror=incompatible-pointer-types]</span>
<span class="err">         .d_compare = ll_dcompare,</span>
<span class="err">                  ^~~~~~~~~~~</span>
<span class="err">/home/dja/dev/lustre-release/debian/tmp/modules-deb/usr_src/modules/lustre/lustre/llite/dcache.c:387:22: note: (near initialization for ‘ll_d_ops.d_compare’)</span>
</code></pre></div>

<p>I figured this was probably because Ubuntu 16.10 has a 4.8 kernel, and Ubuntu 16.04 has a 4.4 kernel. Work on supporting 4.8 <a href="https://jira.hpdd.intel.com/browse/LU-9003">is ongoing</a>.</p>
<p>Sure enough, when I fired up a 16.04 x86_64 VM with a 4.4 kernel, I was able to build and install fine.</p>
<p>Connecting didn't work first time - the guest failed to mount, but I did get the following helpful error on the server:</p>
<div class="highlight"><pre><span></span><code><span class="n">LNetError</span><span class="o">:</span> <span class="mi">2595</span><span class="o">:</span><span class="mi">0</span><span class="o">:(</span><span class="n">acceptor</span><span class="o">.</span><span class="na">c</span><span class="o">:</span><span class="mi">406</span><span class="o">:</span><span class="n">lnet_acceptor</span><span class="o">())</span> <span class="n">Refusing</span> <span class="n">connection</span> <span class="n">from</span> <span class="mf">10.61</span><span class="o">.</span><span class="mf">2.227</span><span class="o">:</span> <span class="n">insecure</span> <span class="n">port</span> <span class="mi">1024</span>
</code></pre></div>

<p>Refusing insecure port 1024 made me thing that perhaps the NATing that qemu was performing for me was interfering - perhaps the server expected to get a connection where the source port was privileged, and qemu wouldn't be able to do that with NAT.</p>
<p>Sure enough, switching NAT to bridging was enough to get the x86 VM to talk to the ppc64le server. I verified that <code>ls</code>, reading and writing all succeeded.</p>
<h1>Next steps</h1>
<p>The obvious next steps are following up the disabled tests in e2fsprogs, and doing a lot of internal performance and functionality testing.</p>
<p>Happily, it looks like Lustre might be in the mainline kernel before too long - parts have already started to go in to staging. This will make our lives a lot easier: for example, the breakage between 4.4 and 4.8 would probably have already been picked up and fixed if it was the main kernel tree rather than an out-of-tree patch set.</p>
<p>In the long run, we'd like to make Lustre on Power just as easy as Lustre on x86. (And, of course, more performant!) We'll keep you up to date!</p>
<p>(Thanks to fellow bloggers Daniel Black and Andrew Donnellan for useful feedback on this post.)</p></div>
  		</article>
  		<article>
<header>
      <h1 class="entry-title">
        <a href="https://sthbrx.github.io/blog/2017/02/01/namd-on-nvlink/">NAMD on NVLink</a>
      </h1>
    <p class="meta">
<time datetime="2017-02-01T08:32:00+11:00" pubdate>Wed 01 February 2017</time>    </p>
</header>

<div class="byline_index">
  <span class="byline author vcard">
    Posted by <span class="fn">
          <a href="https://sthbrx.github.io/author/daniel-axtens.html">Daniel Axtens</a>,
          <a href="https://sthbrx.github.io/author/rashmica-gupta.html">Rashmica Gupta</a>,
          <a href="https://sthbrx.github.io/author/daniel-black.html">Daniel Black</a>
    </span>
  </span>
<time datetime="2017-02-01T08:32:00+11:00" pubdate>Wed 01 February 2017</time></div>

  <div class="entry-content"><p>NAMD is a molecular dynamics program that can use GPU acceleration to speed up its calculations. Recent OpenPOWER machines like the IBM Power Systems S822LC for High Performance Computing (Minsky) come with a new interconnect for GPUs called NVLink, which offers extremely high bandwidth to a number of very powerful Nvidia Pascal P100 GPUs. So they're ideal machines for this sort of workload.</p>
<p>Here's how to set up NAMD 2.12 on your Minsky, and how to debug some common issues. We've targeted this script for CentOS, but we've successfully compiled NAMD on Ubuntu as well.</p>
<h2>Prerequisites</h2>
<h3>GPU Drivers and CUDA</h3>
<p>Firstly, you'll need CUDA and the NVidia drivers.</p>
<p>You can install CUDA by following the instructions on NVidia's <a href="https://developer.nvidia.com/cuda-downloads">CUDA Downloads</a> page.</p>
<div class="highlight"><pre><span></span><code><span class="n">yum</span> <span class="n">install</span> <span class="n">epel</span><span class="o">-</span><span class="n">release</span>
<span class="n">yum</span> <span class="n">install</span> <span class="n">dkms</span>
<span class="c1"># download the rpm from the NVidia website</span>
<span class="n">rpm</span> <span class="o">-</span><span class="n">i</span> <span class="n">cuda</span><span class="o">-</span><span class="n">repo</span><span class="o">-</span><span class="n">rhel7</span><span class="o">-</span><span class="mi">8</span><span class="o">-</span><span class="mi">0</span><span class="o">-</span><span class="n">local</span><span class="o">-</span><span class="n">ga2</span><span class="o">-</span><span class="mf">8.0</span><span class="o">.</span><span class="mi">54</span><span class="o">-</span><span class="mf">1.</span><span class="n">ppc64le</span><span class="o">.</span><span class="n">rpm</span>
<span class="n">yum</span> <span class="n">clean</span> <span class="n">expire</span><span class="o">-</span><span class="n">cache</span>
<span class="n">yum</span> <span class="n">install</span> <span class="n">cuda</span>
<span class="c1"># this will take a while...</span>
</code></pre></div>

<p>Then, we set up a profile file to automatically load CUDA into our path:</p>
<div class="highlight"><pre><span></span><code><span class="n">cat</span> <span class="o">&gt;</span>  <span class="o">/</span><span class="n">etc</span><span class="o">/</span><span class="n">profile</span><span class="o">.</span><span class="n">d</span><span class="o">/</span><span class="n">cuda_path</span><span class="o">.</span><span class="n">sh</span> <span class="o">&lt;&lt;</span><span class="n">EOF</span>
<span class="c1"># From http://developer.download.nvidia.com/compute/cuda/8.0/secure/prod/docs/sidebar/CUDA_Quick_Start_Guide.pdf - 4.4.2.1</span>
<span class="k">export</span> <span class="n">PATH</span><span class="o">=/</span><span class="n">usr</span><span class="o">/</span><span class="n">local</span><span class="o">/</span><span class="n">cuda</span><span class="o">-</span><span class="mf">8.0</span><span class="o">/</span><span class="n">bin</span><span class="o">$</span><span class="p">{</span><span class="n">PATH</span><span class="p">:</span><span class="o">+</span><span class="p">:</span><span class="o">$</span><span class="p">{</span><span class="n">PATH</span><span class="p">}}</span>
<span class="k">export</span> <span class="n">LD_LIBRARY_PATH</span><span class="o">=/</span><span class="n">usr</span><span class="o">/</span><span class="n">local</span><span class="o">/</span><span class="n">cuda</span><span class="o">-</span><span class="mf">8.0</span><span class="o">/</span><span class="n">lib64</span><span class="o">$</span><span class="p">{</span><span class="n">LD_LIBRARY_PATH</span><span class="p">:</span><span class="o">+</span><span class="p">:</span><span class="o">$</span><span class="p">{</span><span class="n">LD_LIBRARY_PATH</span><span class="p">}}</span>
<span class="n">EOF</span>
</code></pre></div>

<p>Now, open a new terminal session and check to see if it works:</p>
<div class="highlight"><pre><span></span><code><span class="err">cuda-install-samples-8.0.sh ~</span>
<span class="err">cd ~/NVIDIA_CUDA-8.0_Samples/1_Utilities/bandwidthTest</span>
<span class="err">make &amp;&amp; ./bandwidthTest</span>
</code></pre></div>

<p>If you see a figure of ~32GB/s, that means NVLink is working as expected. A figure of ~7-8GB indicates that only PCI is working, and more debugging is required.</p>
<h3>Compilers</h3>
<p>You need a c++ compiler:</p>
<div class="highlight"><pre><span></span><code><span class="err">yum install gcc-c++</span>
</code></pre></div>

<h2>Building NAMD</h2>
<p>Once CUDA and the compilers are installed, building NAMD is reasonably straightforward. The one hitch is that because we're using CUDA 8.0, and the NAMD build scripts assume CUDA 7.5, we need to supply an updated <a href="/images/namd/Linux-POWER.cuda">Linux-POWER.cuda file</a>. (We also enable code generation for the Pascal in this file.)</p>
<p>We've documented the entire process as a script which you can <a href="/images/namd/install-namd.sh">download</a>. We'd recommend executing the commands one by one, but if you're brave you can run the script directly.</p>
<p>The script will fetch NAMD 2.12 and build it for you, but won't install it. It will look for the CUDA override file in the directory you are running the script from, and will automatically move it into the correct place so it is picked up by the build system..</p>
<p>The script compiles for a single multicore machine setup, rather than for a cluster. However, it should be a good start for an Ethernet or Infiniband setup.</p>
<p>If you're doing things by hand, you may see some errors during the compilation of charm - as long as you get <code>charm++ built successfully.</code> at the end, you should be OK.</p>
<h2>Testing NAMD</h2>
<p>We have been testing NAMD using the STMV files available from the <a href="http://www.ks.uiuc.edu/Research/namd/utilities/">NAMD website</a>:</p>
<div class="highlight"><pre><span></span><code><span class="err">cd NAMD_2.12_Source/Linux-POWER-g++</span>
<span class="err">wget http://www.ks.uiuc.edu/Research/namd/utilities/stmv.tar.gz</span>
<span class="err">tar -xf stmv.tar.gz</span>
<span class="err">sudo ./charmrun +p80 ./namd2 +pemap 0-159:2 +idlepoll +commthread stmv/stmv.namd</span>
</code></pre></div>

<p>This binds a namd worker thread to every second hardware thread. This is because hardware threads share resources, so using every hardware thread costs overhead and doesn't give us access to any more physical resources.</p>
<p>You should see messages about finding and using GPUs:</p>
<div class="highlight"><pre><span></span><code><span class="err">Pe 0 physical rank 0 binding to CUDA device 0 on &lt;hostname&gt;: &#39;Graphics Device&#39;  Mem: 4042MB  Rev: 6.0</span>
</code></pre></div>

<p>This should be <em>significantly</em> faster than on non-NVLink machines - we saw a gain of about 2x in speed going from a machine with Nvidia K80s to a Minsky. If things aren't faster for you, let us know!</p>
<h2>Downloads</h2>
<ul>
<li><a href="/images/namd/install-namd.sh">Install script for CentOS</a></li>
<li><a href="/images/namd/Linux-POWER.cuda">Linux-POWER.cuda file</a></li>
</ul>
<h2>Other notes</h2>
<p>Namd requires some libraries, some of which they supply as binary downloads on <a href="http://www.ks.uiuc.edu/Research/namd/libraries/">their website</a>.
Make sure you get the ppc64le versions, not the ppc64 versions, otherwise you'll get errors like:</p>
<div class="highlight"><pre><span></span><code><span class="err">/bin/ld: failed to merge target specific data of file .rootdir/tcl/lib/libtcl8.5.a(regfree.o)</span>
<span class="err">/bin/ld: .rootdir/tcl/lib/libtcl8.5.a(regerror.o): compiled for a big endian system and target is little endian</span>
<span class="err">/bin/ld: failed to merge target specific data of file .rootdir/tcl/lib/libtcl8.5.a(regerror.o)</span>
<span class="err">/bin/ld: .rootdir/tcl/lib/libtcl8.5.a(tclAlloc.o): compiled for a big endian system and target is little endian</span>
</code></pre></div>

<p>The script we supply should get these right automatically.</p></div>
  		</article>
  		<article>
<header>
      <h1 class="entry-title">
        <a href="https://sthbrx.github.io/blog/2017/01/31/linuxconfau-2017-review/">linux.conf.au 2017 review</a>
      </h1>
    <p class="meta">
<time datetime="2017-01-31T16:07:00+11:00" pubdate>Tue 31 January 2017</time>    </p>
</header>

<div class="byline_index">
  <span class="byline author vcard">
    Posted by <span class="fn">
          <a href="https://sthbrx.github.io/author/daniel-axtens.html">Daniel Axtens</a>
    </span>
  </span>
<time datetime="2017-01-31T16:07:00+11:00" pubdate>Tue 31 January 2017</time></div>

  <div class="entry-content"><p>I recently attended LCA 2017, where I gave a talk at the Linux Kernel miniconf (run by fellow sthbrx blogger Andrew Donnellan!) and a talk at the main conference.</p>
<p>I received some really interesting feedback so I've taken the opportunity to write some of it down to complement the talk videos and slides that are online. (And to remind me to follow up on it!)</p>
<h2>Miniconf talk: Sparse Warnings</h2>
<p>My kernel miniconf talk was on sparse warnings (<a href="https://github.com/daxtens/sparse-warnings-talk/blob/master/talk.pdf">pdf slides</a>, <a href="https://www.youtube.com/watch?v=hmCukzpevUc">23m video</a>).</p>
<p>The abstract read (in part):</p>
<blockquote>
<p>sparse is a semantic parser for C, and is one of the static analysis tools available to kernel devs.</p>
<p>Sparse is a powerful tool with good integration into the kernel build system. However, we suffer from warning overload - there are too many sparse warnings to spot the serious issues amongst the trivial. This makes it difficult to use, both for developers and maintainers.</p>
</blockquote>
<p>Happily, I received some feedback that suggests it's not all doom and gloom like I had thought!</p>
<ul>
<li>
<p>Dave Chinner told me that the xfs team uses sparse regularly to make sure that the file system is endian-safe. This is good news - we really would like that to be endian-safe!</p>
</li>
<li>
<p>Paul McKenney let me know that the 0day bot does do some sparse checking - it would just seem that it's not done on PowerPC.</p>
</li>
</ul>
<h2>Main talk: 400,000 Ephemeral Containers</h2>
<p>My main talk was entitled "400,000 Ephemeral Containers: testing entire ecosystems with Docker". You can read the <a href="https://linux.conf.au/schedule/presentation/81/">abstract</a> for full details, but it boils down to:</p>
<blockquote>
<p>What if you want to test how <em>all</em> the packages in a given ecosystem work in a given situation?</p>
</blockquote>
<p>My main example was testing how many of the Ruby packages successfully install on Power, but I also talk about other languages and other cool tests you could run.</p>
<p>The <a href="https://www.youtube.com/watch?v=v7wSqOQeGhA">44m video</a> is online. I haven't put the slides up yet but they should be available <a href="https://github.com/daxtens/400000-ephemeral-containers">on GitHub</a> soonish.</p>
<p>Unlike with the kernel talk, I didn't catch the names of most of the people with feedback.</p>
<h3>Docker memory issues</h3>
<p>One of the questions I received during the talk was about running into memory issues in Docker. I attempted to answer that during the Q&amp;A. The person who asked the question then had a chat with me afterwards, and it turns out I had completely misunderstood the question. I thought it was about memory usage of running containers in parallel. It was actually about memory usage in the docker daemon when running lots of containers in serial. Apparently the docker daemon doesn't free memory during the life of the process, and the question was whether or not I had observed that during my runs.</p>
<p>I didn't have a good answer for this at the time other than "it worked for me", so I have gone back and looked at the docker daemon memory usage.</p>
<p>After a full Ruby run, the daemon is using about 13.9G of virtual memory, and 1.975G of resident memory. If I restart it, the memory usage drops to 1.6G of virtual and 43M of resident memory. So it would appear that the person asking the question was right, and I'm just not seeing it have an effect.</p>
<h3>Other interesting feedback</h3>
<ul>
<li>
<p>Someone was quite interested in testing on Sparc, once they got their Go runtime nailed down.</p>
</li>
<li>
<p>A Rackspacer was quite interested in Python testing for OpenStack - this has some intricacies around Py2/Py3, but we had an interesting discussion around just testing to see if packages that claim Py3 support provide Py3 support.</p>
</li>
<li>
<p>A large jobs site mentioned using this technique to help them migrate their dependencies between versions of Go.</p>
</li>
<li>
<p>I was 'gently encouraged' to try to do better with how long the process takes to run - if for no other reason than to avoid burning more coal. This is a fair point. I did not explain very well what I meant with diminishing returns in the talk: there's <em>lots</em> you could do to make the process faster, it's just comes at the cost of the simplicity that I really wanted when I first started the project. I am working (on and off) on better ways to deal with this by considering the dependency graph.</p>
</li>
</ul></div>
  		</article>
  		<article>
<header>
      <h1 class="entry-title">
        <a href="https://sthbrx.github.io/blog/2017/01/30/extracting-early-boot-messages-in-qemu/">Extracting Early Boot Messages in QEMU</a>
      </h1>
    <p class="meta">
<time datetime="2017-01-30T16:47:00+11:00" pubdate>Mon 30 January 2017</time>    </p>
</header>

<div class="byline_index">
  <span class="byline author vcard">
    Posted by <span class="fn">
          <a href="https://sthbrx.github.io/author/suraj-jitindar-singh.html">Suraj Jitindar Singh</a>
    </span>
  </span>
<time datetime="2017-01-30T16:47:00+11:00" pubdate>Mon 30 January 2017</time></div>

  <div class="entry-content"><p>Be me, you're a kernel hacker, you make some changes to your kernel, you boot
test it in QEMU, and it fails to boot. Even worse is the fact that it just hangs
without any failure message, no stack trace, no nothing. "Now what?" you think
to yourself.</p>
<p>You probably do the first thing you learnt in debugging101 and add abundant
print statements all over the place to try and make some sense of what's
happening and where it is that you're actually crashing. So you do this, you
recompile your kernel, boot it in QEMU and lo and behold, nothing... What
happened? You added all these shiny new print statements, where did the output
go? The kernel still failed to boot (obviously), but where you were hoping to
get some clue to go on you were again left with an empty screen. "Maybe I
didn't print early enough" or "maybe I got the code paths wrong" you think,
"maybe I just need more prints" even. So lets delve a bit deeper, why didn't
you see those prints, where did they go, and how can you get at them?</p>
<h1>__log_buf</h1>
<p>So what happens when you call printk()? Well what normally happens is,
depending on the log level you set, the output is sent to the console or logged
so you can see it in dmesg. But what happens if we haven't registered a console
yet? Well then we can't print the message can we, so its logged in a buffer,
kernel log buffer to be exact helpfully named __log_buf.</p>
<h1>Console Registration</h1>
<p>So how come I eventually see print statements on my screen? Well at some point
during the boot process a console is registered with the printk system, and any
buffered output can now be displayed. On ppc it happens that this occurs in
register_early_udbg_console() called in setup_arch() from start_kernel(),
which is the generic kernel entry point. From this point forward when you print
something it will be displayed on the console, but what if you crash before
this? What are you supposed to do then?</p>
<h1>Extracting Early Boot Messages in QEMU</h1>
<p>And now the moment you've all been waiting for, how do I extract those early
boot messages in QEMU if my kernel crashes before the console is registered?
Well it's quite simple really, QEMU is nice enough to allow us to dump guest
memory, and we know the log buffer is in there some where, so we just need to
dump the correct part of memory which corresponds to the log buffer.</p>
<h4>Locating __log_buf</h4>
<p>Before we can dump the log buffer we need to know where it is. Luckily for us
this is fairly simple, we just need to dump all the kernel symbols and look for
the right one.</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;</span> <span class="n">nm</span> <span class="n">vmlinux</span> <span class="o">&gt;</span> <span class="n">tmp</span><span class="p">;</span> <span class="n">grep</span> <span class="n">__log_buf</span> <span class="n">tmp</span><span class="p">;</span>
<span class="n">c000000000f5e3dc</span> <span class="n">b</span> <span class="n">__log_buf</span>
</code></pre></div>

<p>We use the nm tool to list all the kernel symbols and output this into some
temporary file, we can then grep this for the log buffer (which we know to be
named __log_buf), and presto we are told that it's at kernel address 0xf5e3dc.</p>
<h4>Dumping Guest Memory</h4>
<p>It's then simply a case of dumping guest memory from the QEMU console. So first
we press ^a+c to get us to the QEMU console, then we can use the aptly named
dump-guest-memory.</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;</span> <span class="n">help</span> <span class="n">dump</span><span class="o">-</span><span class="n">guest</span><span class="o">-</span><span class="n">memory</span>
<span class="n">dump</span><span class="o">-</span><span class="n">guest</span><span class="o">-</span><span class="n">memory</span> <span class="p">[</span><span class="o">-</span><span class="n">p</span><span class="p">]</span> <span class="p">[</span><span class="o">-</span><span class="n">d</span><span class="p">]</span> <span class="p">[</span><span class="o">-</span><span class="n">z</span><span class="o">|-</span><span class="n">l</span><span class="o">|-</span><span class="n">s</span><span class="p">]</span> <span class="n">filename</span> <span class="p">[</span><span class="n">begin</span> <span class="n">length</span><span class="p">]</span> <span class="o">--</span> <span class="n">dump</span> <span class="n">guest</span> <span class="n">memory</span> <span class="n">into</span> <span class="n">file</span> <span class="err">&#39;</span><span class="n">filename</span><span class="err">&#39;</span><span class="p">.</span>
            <span class="o">-</span><span class="nl">p</span><span class="p">:</span> <span class="k">do</span> <span class="n">paging</span> <span class="n">to</span> <span class="n">get</span> <span class="n">guest</span><span class="err">&#39;</span><span class="n">s</span> <span class="n">memory</span> <span class="n">mapping</span><span class="p">.</span>
            <span class="o">-</span><span class="nl">d</span><span class="p">:</span> <span class="k">return</span> <span class="n">immediately</span> <span class="p">(</span><span class="k">do</span> <span class="n">not</span> <span class="n">wait</span> <span class="k">for</span> <span class="n">completion</span><span class="p">).</span>
            <span class="o">-</span><span class="nl">z</span><span class="p">:</span> <span class="n">dump</span> <span class="n">in</span> <span class="n">kdump</span><span class="o">-</span><span class="n">compressed</span> <span class="n">format</span><span class="p">,</span> <span class="n">with</span> <span class="n">zlib</span> <span class="n">compression</span><span class="p">.</span>
            <span class="o">-</span><span class="nl">l</span><span class="p">:</span> <span class="n">dump</span> <span class="n">in</span> <span class="n">kdump</span><span class="o">-</span><span class="n">compressed</span> <span class="n">format</span><span class="p">,</span> <span class="n">with</span> <span class="n">lzo</span> <span class="n">compression</span><span class="p">.</span>
            <span class="o">-</span><span class="nl">s</span><span class="p">:</span> <span class="n">dump</span> <span class="n">in</span> <span class="n">kdump</span><span class="o">-</span><span class="n">compressed</span> <span class="n">format</span><span class="p">,</span> <span class="n">with</span> <span class="n">snappy</span> <span class="n">compression</span><span class="p">.</span>
            <span class="nl">begin</span><span class="p">:</span> <span class="n">the</span> <span class="n">starting</span> <span class="n">physical</span> <span class="n">address</span><span class="p">.</span>
            <span class="nl">length</span><span class="p">:</span> <span class="n">the</span> <span class="n">memory</span> <span class="n">size</span><span class="p">,</span> <span class="n">in</span> <span class="n">bytes</span><span class="p">.</span>
</code></pre></div>

<p>We just give it a filename for where we want our output to go, we know the
starting address, we just don't know the length. We could choose some arbitrary
length, but inspection of the kernel code shows us that:</p>
<div class="highlight"><pre><span></span><code><span class="cp">#define __LOG_BUF_LEN (1 &lt;&lt; CONFIG_LOG_BUF_SHIFT)</span>
<span class="k">static</span> <span class="kt">char</span> <span class="n">__log_buf</span><span class="p">[</span><span class="n">__LOG_BUF_LEN</span><span class="p">]</span> <span class="n">__aligned</span><span class="p">(</span><span class="n">LOG_ALIGN</span><span class="p">);</span>
</code></pre></div>

<p>Looking at the pseries_defconfig file shows us that the LOG_BUF_SHIFT is set to
18, and thus we know that the buffer is 2^18 bytes or 256kb. So now we run:</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;</span> <span class="n">dump</span><span class="o">-</span><span class="n">guest</span><span class="o">-</span><span class="n">memory</span> <span class="n">tmp</span> <span class="mh">0xf5e3dc</span> <span class="mi">262144</span>
</code></pre></div>

<p>And we now get our log buffer in the file tmp. This can simply be viewed with:</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;</span> <span class="n">hexdump</span> <span class="o">-</span><span class="n">C</span> <span class="n">tmp</span>
</code></pre></div>

<p>This gives a readable, if poorly formatted output. I'm sure you can find
something better but I'll leave that as an exercise for the reader.</p>
<h1>Conclusion</h1>
<p>So if like me your kernel hangs somewhere early in the boot process and you're
left without your console output you are now fully equipped to extract the log
buffer in QEMU and hopefully therein lies the answer to why you failed to boot.</p></div>
  		</article>
<div class="pagination">
    <a class="prev" href="https://sthbrx.github.io/index6.html">&larr; Older</a>

    <a class="next" href="https://sthbrx.github.io/index4.html">Newer &rarr;</a>
  <br />
</div></div>
<aside class="sidebar">
  <section>
    <h1>Recent Posts</h1>
    <ul id="recent_posts">
      <li class="post">
          <a href="https://sthbrx.github.io/blog/2021/06/14/fuzzing-grub-part-2-going-faster/">Fuzzing grub, part 2: going faster</a>
      </li>
      <li class="post">
          <a href="https://sthbrx.github.io/blog/2021/03/04/fuzzing-grub-part-1/">Fuzzing grub: part 1</a>
      </li>
      <li class="post">
          <a href="https://sthbrx.github.io/blog/2020/01/22/linuxconfau-2020-recap/">linux.conf.au 2020 recap</a>
      </li>
      <li class="post">
          <a href="https://sthbrx.github.io/blog/2019/12/18/rfid-and-hrfid/">rfid and hrfid</a>
      </li>
      <li class="post">
          <a href="https://sthbrx.github.io/blog/2019/06/18/ten-thousand-disks/">TEN THOUSAND DISKS</a>
      </li>
    </ul>
  </section>
  <section>
      
    <h1>Categories</h1>
    <ul id="recent_posts">
        <li><a href="https://sthbrx.github.io/category/development.html">Development</a></li>
        <li><a href="https://sthbrx.github.io/category/education.html">Education</a></li>
        <li><a href="https://sthbrx.github.io/category/openpower.html">OpenPOWER</a></li>
        <li><a href="https://sthbrx.github.io/category/performance.html">Performance</a></li>
        <li><a href="https://sthbrx.github.io/category/petitboot.html">Petitboot</a></li>
        <li><a href="https://sthbrx.github.io/category/snowpatch.html">snowpatch</a></li>
        <li><a href="https://sthbrx.github.io/category/virtualisation-and-emulation.html">Virtualisation and Emulation</a></li>
    </ul>
  </section>
 

  <section>
  <h1>Tags</h1>
    <a href="https://sthbrx.github.io/tag/testing.html">testing</a>,    <a href="https://sthbrx.github.io/tag/conferences.html">conferences</a>,    <a href="https://sthbrx.github.io/tag/instruction-set-architecture.html">Instruction Set Architecture</a>,    <a href="https://sthbrx.github.io/tag/openpower.html">openpower</a>,    <a href="https://sthbrx.github.io/tag/linux.html">linux</a>,    <a href="https://sthbrx.github.io/tag/firmware.html">firmware</a>,    <a href="https://sthbrx.github.io/tag/goodposts.html">goodposts</a>,    <a href="https://sthbrx.github.io/tag/realcontent.html">realcontent</a>,    <a href="https://sthbrx.github.io/tag/madposting.html">madposting</a>,    <a href="https://sthbrx.github.io/tag/op-test.html">op-test</a>,    <a href="https://sthbrx.github.io/tag/qemu.html">qemu</a>,    <a href="https://sthbrx.github.io/tag/pci.html">pci</a>,    <a href="https://sthbrx.github.io/tag/sparseposting.html">sparseposting</a>,    <a href="https://sthbrx.github.io/tag/petitboot.html">petitboot</a>,    <a href="https://sthbrx.github.io/tag/security.html">security</a>,    <a href="https://sthbrx.github.io/tag/vscode.html">vscode</a>,    <a href="https://sthbrx.github.io/tag/code.html">code</a>,    <a href="https://sthbrx.github.io/tag/openbmc.html">openbmc</a>,    <a href="https://sthbrx.github.io/tag/ipmi.html">ipmi</a>,    <a href="https://sthbrx.github.io/tag/opencapi.html">opencapi</a>,    <a href="https://sthbrx.github.io/tag/openpower-summit.html">openpower summit</a>,    <a href="https://sthbrx.github.io/tag/easyposts.html">easyposts</a>,    <a href="https://sthbrx.github.io/tag/linuxboot.html">linuxboot</a>,    <a href="https://sthbrx.github.io/tag/google.html">google</a>,    <a href="https://sthbrx.github.io/tag/intel.html">intel</a>,    <a href="https://sthbrx.github.io/tag/osfc.html">osfc</a>,    <a href="https://sthbrx.github.io/tag/shortposts.html">shortposts</a>,    <a href="https://sthbrx.github.io/tag/facebook.html">facebook</a>,    <a href="https://sthbrx.github.io/tag/performance.html">performance</a>,    <a href="https://sthbrx.github.io/tag/phoronix.html">phoronix</a>,    <a href="https://sthbrx.github.io/tag/benchmarks.html">benchmarks</a>,    <a href="https://sthbrx.github.io/tag/kernel.html">kernel</a>,    <a href="https://sthbrx.github.io/tag/stupid-ideas.html">stupid ideas</a>,    <a href="https://sthbrx.github.io/tag/network.html">network</a>,    <a href="https://sthbrx.github.io/tag/power.html">power</a>,    <a href="https://sthbrx.github.io/tag/xdp.html">xdp</a>,    <a href="https://sthbrx.github.io/tag/networking.html">networking</a>,    <a href="https://sthbrx.github.io/tag/remoteposts.html">remoteposts</a>,    <a href="https://sthbrx.github.io/tag/ceph.html">ceph</a>,    <a href="https://sthbrx.github.io/tag/raid.html">raid</a>,    <a href="https://sthbrx.github.io/tag/storage.html">storage</a>,    <a href="https://sthbrx.github.io/tag/erasure.html">erasure</a>,    <a href="https://sthbrx.github.io/tag/lustre.html">lustre</a>,    <a href="https://sthbrx.github.io/tag/hpc.html">hpc</a>,    <a href="https://sthbrx.github.io/tag/nvlink.html">nvlink</a>,    <a href="https://sthbrx.github.io/tag/namd.html">namd</a>,    <a href="https://sthbrx.github.io/tag/cuda.html">cuda</a>,    <a href="https://sthbrx.github.io/tag/gpu.html">gpu</a>,    <a href="https://sthbrx.github.io/tag/minsky.html">minsky</a>,    <a href="https://sthbrx.github.io/tag/s822lc-for-hpc.html">S822LC for hpc</a>,    <a href="https://sthbrx.github.io/tag/debug.html">debug</a>,    <a href="https://sthbrx.github.io/tag/virtualisation.html">virtualisation</a>,    <a href="https://sthbrx.github.io/tag/dmesg.html">dmesg</a>,    <a href="https://sthbrx.github.io/tag/printk.html">printk</a>,    <a href="https://sthbrx.github.io/tag/boot.html">boot</a>,    <a href="https://sthbrx.github.io/tag/early.html">early</a>,    <a href="https://sthbrx.github.io/tag/error.html">error</a>,    <a href="https://sthbrx.github.io/tag/centos.html">centos</a>,    <a href="https://sthbrx.github.io/tag/centos7.html">centos7</a>,    <a href="https://sthbrx.github.io/tag/p8.html">p8</a>,    <a href="https://sthbrx.github.io/tag/bmc.html">bmc</a>,    <a href="https://sthbrx.github.io/tag/rhel.html">RHEL</a>,    <a href="https://sthbrx.github.io/tag/skiroot.html">skiroot</a>,    <a href="https://sthbrx.github.io/tag/devmapper.html">devmapper</a>,    <a href="https://sthbrx.github.io/tag/lvm.html">lvm</a>,    <a href="https://sthbrx.github.io/tag/cgroups.html">cgroups</a>,    <a href="https://sthbrx.github.io/tag/numa.html">numa</a>,    <a href="https://sthbrx.github.io/tag/development.html">Development</a>,    <a href="https://sthbrx.github.io/tag/netboot.html">netboot</a>,    <a href="https://sthbrx.github.io/tag/pxe.html">pxe</a>,    <a href="https://sthbrx.github.io/tag/education.html">Education</a>,    <a href="https://sthbrx.github.io/tag/work-experience.html">work experience</a>,    <a href="https://sthbrx.github.io/tag/asm.html">asm</a>,    <a href="https://sthbrx.github.io/tag/vdso.html">vdso</a>,    <a href="https://sthbrx.github.io/tag/snowpatch.html">snowpatch</a>,    <a href="https://sthbrx.github.io/tag/tools.html">tools</a>,    <a href="https://sthbrx.github.io/tag/intern.html">intern</a>,    <a href="https://sthbrx.github.io/tag/srop.html">SROP</a>,    <a href="https://sthbrx.github.io/tag/mitigation.html">mitigation</a>,    <a href="https://sthbrx.github.io/tag/double.html">double</a>,    <a href="https://sthbrx.github.io/tag/float.html">float</a>,    <a href="https://sthbrx.github.io/tag/hex.html">hex</a>,    <a href="https://sthbrx.github.io/tag/debugging.html">debugging</a>,    <a href="https://sthbrx.github.io/tag/skiboot.html">skiboot</a>,    <a href="https://sthbrx.github.io/tag/opal.html">OPAL</a>,    <a href="https://sthbrx.github.io/tag/fsp.html">FSP</a>,    <a href="https://sthbrx.github.io/tag/patches.html">patches</a>,    <a href="https://sthbrx.github.io/tag/based16.html">based16</a>,    <a href="https://sthbrx.github.io/tag/linux-gods.html">Linux Gods</a>,    <a href="https://sthbrx.github.io/tag/ozlabs.html">Ozlabs</a>,    <a href="https://sthbrx.github.io/tag/offtopic.html">offtopic</a>,    <a href="https://sthbrx.github.io/tag/autoboot.html">autoboot</a>,    <a href="https://sthbrx.github.io/tag/kexec.html">kexec</a>,    <a href="https://sthbrx.github.io/tag/aufs.html">aufs</a>,    <a href="https://sthbrx.github.io/tag/overlay.html">overlay</a>,    <a href="https://sthbrx.github.io/tag/php.html">php</a>,    <a href="https://sthbrx.github.io/tag/capi.html">capi</a>  </section>

  <section>
    <h1><a href="https://sthbrx.github.io/authors.html">Authors</a></h1>
    <ul id="authors_list">
        <li><a href="https://sthbrx.github.io/author/alastair-dsilva.html">Alastair D'Silva</a></li>
        <li><a href="https://sthbrx.github.io/author/andrew-donnellan.html">Andrew Donnellan</a></li>
        <li><a href="https://sthbrx.github.io/author/anton-blanchard.html">Anton Blanchard</a></li>
        <li><a href="https://sthbrx.github.io/author/callum-scarvell.html">Callum Scarvell</a></li>
        <li><a href="https://sthbrx.github.io/author/cyril-bur.html">Cyril Bur</a></li>
        <li><a href="https://sthbrx.github.io/author/daniel-axtens.html">Daniel Axtens</a></li>
        <li><a href="https://sthbrx.github.io/author/daniel-black.html">Daniel Black</a></li>
        <li><a href="https://sthbrx.github.io/author/joel-stanley.html">Joel Stanley</a></li>
        <li><a href="https://sthbrx.github.io/author/nick-piggin.html">Nick Piggin</a></li>
        <li><a href="https://sthbrx.github.io/author/rashmica-gupta.html">Rashmica Gupta</a></li>
        <li><a href="https://sthbrx.github.io/author/rohan-mclure.html">Rohan McLure</a></li>
        <li><a href="https://sthbrx.github.io/author/russell-currey.html">Russell Currey</a></li>
        <li><a href="https://sthbrx.github.io/author/samuel-mendoza-jonas.html">Samuel Mendoza-Jonas</a></li>
        <li><a href="https://sthbrx.github.io/author/suraj-jitindar-singh.html">Suraj Jitindar Singh</a></li>
    </ul>
  </section>


    <section>
        <h1>Social</h1>
        <ul>
            <li><a href="https://sthbrx.github.io/rss.xml" type="application/rss+xml" rel="alternate">RSS</a></li>
            <li><a href="https://github.com/sthbrx/" target="_blank">GitHub</a></li>
            <li><a href="https://lists.ozlabs.org/listinfo/linuxppc-dev" target="_blank">linuxppc mailing list</a></li>
            <li><a href="https://lists.ozlabs.org/listinfo/skiboot" target="_blank">Skiboot mailing list</a></li>
        </ul>
    </section>
    <section>
        <h1>Blogroll</h1>
        <ul>
            <li><a href="http://ozlabs.org" target="_blank">OzLabs</a></li>
        </ul>
    </section>

    <section>
        <h1>Disclaimer</h1>
        <div>
This blog represents the views of the individual authors, and doesn't necessarily represent IBM's positions, strategies or opinions.        </div>
    </section>
</aside>    </div>
  </div>
  <footer role="contentinfo"><p>
    Copyright &copy;  2015&ndash;2021  OzLabs &mdash;
  <span class="credit">Powered by <a href="http://getpelican.com">Pelican</a></span>
</p></footer>
</body>
</html>